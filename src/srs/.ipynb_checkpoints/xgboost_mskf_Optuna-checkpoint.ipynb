{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672cd7e5-7478-4b75-a4db-810476f06233",
   "metadata": {},
   "source": [
    "# tabpfn_xgboost_mskf.ipynb\n",
    "## 実験条件\n",
    "* 学習時にgreeks.csvのEpsilon使用, テストデータでは訓練データのEpsilonの最大値+1とする\n",
    "* 欠損値は中央値で補完\n",
    "* greeks.csvのAlphaを予測、予測後にA->0, (B, G, D)->1に変換\n",
    "* CVはMultilabelStratifiedKFoldで、Beta, Gamma, Deltaのクラス割合が同じになるように分割\n",
    "### 結果\n",
    "* CV: 0.19097697170787517\n",
    "## 変更点(2023-08-05 20:59)\n",
    "* XGBClassifierのsample_weightを設定\n",
    "* sample_weightを計算するためにAlphaをラベルエンコーディング\n",
    "### 結果\n",
    "* CV: 0.18313566432976108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b8938-dc60-4a04-b7d3-d3b2ec25170c",
   "metadata": {},
   "source": [
    "## TabPFNのインストール\n",
    "### 事前にダウンロードするファイル: \n",
    "* TabPFN: <https://www.kaggle.com/datasets/carlmcbrideellis/tabpfn-019-whl>\n",
    "* MultilabelStratifiedKFold: <https://www.kaggle.com/datasets/tilii7/iterative-stratification-017>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d61f413-8b49-4e6f-b89d-491fbbb50abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KaggleNotebookではコメントアウトを外す\n",
    "# !pip install -q /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n",
    "# !mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/\n",
    "# !pip install -q /kaggle/input/iterative-stratification-017/iterative_stratification-0.1.7-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f9a60a-4bfa-423b-b613-a372d4c63685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "# model\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import lightgbm as lgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "# over/under sampling\n",
    "from imblearn.over_sampling import SMOTE # SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif# Feature Selection\n",
    "import category_encoders as encoders\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "# cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "# others\n",
    "from datetime import date, datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# 環境を指定\n",
    "env = 'local'\n",
    "# env = 'kaggle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d4b8a-f3c7-4274-8f37-b40dd2fe7008",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39222989-8739-458c-99c0-c4cff87d149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリの指定\n",
    "if env == 'local':\n",
    "    BASE_DIR = '../../data'\n",
    "elif env == 'kaggle':\n",
    "    BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions/'\n",
    "else:\n",
    "    raise ValueError(\"Invalid environment. Set env as 'local' or 'kaggle'.\")\n",
    "\n",
    "# データの読み込み\n",
    "train_df = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "# train_df = pd.read_csv(f'{BASE_DIR}/train_integerized.csv')\n",
    "greeks_df = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "test_df = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "submission_df = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n",
    "\n",
    "# greeksと結合\n",
    "train_df = pd.merge(train_df, greeks_df[['Id', 'Alpha', 'Epsilon']], on='Id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e192c07-7cc0-43b3-940a-795381b7d93c",
   "metadata": {},
   "source": [
    "greeksのAはClass0に、B, G, DはClass1に相当"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f050385-9970-4624-8654-8ed504030602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alpha\n",
       "A    509\n",
       "B     61\n",
       "G     29\n",
       "D     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeks_df.Alpha.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788c1eb-f369-4df1-980a-587c443c43c1",
   "metadata": {},
   "source": [
    "## Epsilonを特徴量に追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3e3b4b-c47c-499e-a6cf-0b1f42ad96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値以外の日付をグレゴリオ暦の序数形式（1年1月1日を1とし、1日ずつ増やしていく）に変換\n",
    "train_df.Epsilon[train_df.Epsilon != 'Unknown'] = train_df.Epsilon[train_df.Epsilon != 'Unknown']\\\n",
    "                                        .map(lambda x: datetime.strptime(x, '%m/%d/%Y').toordinal())\n",
    "# 欠損値をnp.nanに変換\n",
    "train_df.Epsilon[train_df.Epsilon == 'Unknown'] = np.nan\n",
    "\n",
    "# 訓練データを説明変数と目的変数に分割\n",
    "X_train = train_df.drop(['Id', 'EJ', 'Alpha', 'Class'], axis=1)\n",
    "y_train = train_df[['Class', 'Alpha']]\n",
    "\n",
    "# テストデータから数値データ以外を削除\n",
    "X_test = test_df.drop(['Id', 'EJ'], axis=1)\n",
    "\n",
    "# テストデータは訓練データの最大値+1とする\n",
    "X_test['Epsilon'] = train_df.Epsilon.max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19307475-d571-443e-9464-bc470dedb377",
   "metadata": {},
   "source": [
    "## Alphaをラベルエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fa65ec-8711-4b29-af4f-eab77e820be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# ラベルエンコーダを初期化\n",
    "le = LabelEncoder()\n",
    "# yを数値に変換\n",
    "y_train['Alpha'] = le.fit_transform(y_train['Alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f0d3f-a35a-4580-b460-8cadbfc74f85",
   "metadata": {},
   "source": [
    "self.models = [XGBClassifier(eta=0.01267942116017827, \n",
    "                             gamma=0.0035099486546295838,\n",
    "                             max_depth=10,\n",
    "                             min_child_weight=0.00295968493319233,\n",
    "                             max_delta_step=3.207138802851332e-05,\n",
    "                             subsample=0.17568276820923612,\n",
    "                             reg_lambda=76.82036507955048,\n",
    "                             reg_alpha=812.280448836668,\n",
    "                             n_estimators=100,\n",
    "                             learning_rate=0.2,\n",
    "                             colsample_bytree=0.85),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c29971-dd6e-4f2c-8b4f-808901cbea86",
   "metadata": {},
   "source": [
    "## モデル、評価基準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebac07ef-bc76-468e-af4c-9270e567beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedEns(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.models = [\n",
    "                       XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n",
    "                       # TabPFNClassifier(N_ensemble_configurations=256,device='cuda:0')\n",
    "                      ]\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        # self.imputer = KNNImputer(n_neighbors=50)\n",
    "    \n",
    "    def fit(self, X, y, weights=None):\n",
    "        classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = classes\n",
    "        X = self.imputer.fit_transform(X)\n",
    "        for i, model in enumerate(self.models):\n",
    "            if isinstance(model, XGBClassifier):\n",
    "                model.fit(X, y, sample_weight=weights) # 決定木ではweightを考慮する\n",
    "            else:\n",
    "                model.fit(X,y)\n",
    "    def set_params(self, params):\n",
    "        self.models[0].set_params(**params)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imputer.transform(X)\n",
    "        ps = np.stack([model.predict_proba(X) for model in self.models])\n",
    "        p = np.mean(ps,axis=0)\n",
    "        class_0_est_instances = p[:,0].sum()\n",
    "        others_est_instances = p[:,1:].sum()\n",
    "        # we reweight the probs, since the loss is also balanced like this\n",
    "        # our models out of the box optimize CE\n",
    "        # with these changes they optimize balanced CE\n",
    "        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n",
    "        new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "        return np.concatenate((new_p[:,:1],np.sum(new_p[:,1:],1,keepdims=True)), 1)\n",
    "\n",
    "# 評価基準\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4d20d4-ec2a-4f00-8af2-5905fb70a61c",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3817509a-25d9-42e3-ad07-d1a077ac301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期値\n",
    "seed = 779292\n",
    "folds = 10\n",
    "labels = greeks_df[['Beta', 'Gamma', 'Delta']] # クロスバリデーションの分割で考慮する特徴量\n",
    "\n",
    "def objective(trial):\n",
    "    # 各分割ごとのバリデーションスコアを格納\n",
    "    scores = 0\n",
    "    # クロスバリデーションの分割数を指定\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # ハイパーパラメータのサーチ空間を定義\n",
    "    params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.2,\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-5, 1.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-5, 1.0, log=True)\n",
    "    }\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, labels)):\n",
    "        # 訓練データを分割\n",
    "        X_train_fold = X_train.iloc[train_index]\n",
    "        y_train_fold = y_train['Alpha'].iloc[train_index]\n",
    "        X_valid_fold = X_train.iloc[valid_index]\n",
    "        y_valid_fold = y_train['Class'].iloc[valid_index]\n",
    "    \n",
    "        # Alphaのラベルに重みづけをする\n",
    "        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_fold)\n",
    "        model = WeightedEns()\n",
    "        model.set_params(params)\n",
    "        model.fit(X_train_fold, y_train_fold, weights=sample_weights)\n",
    "        valid_preds = model.predict_proba(X_valid_fold)[:, 1]\n",
    "        val_score = balanced_log_loss(y_valid_fold, valid_preds)\n",
    "        scores += val_score\n",
    "\n",
    "    cv_score = scores / folds\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc3f0a-8e6f-45bd-aeeb-d9568a8b0651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:28:47,025] A new study created in memory with name: no-name-b970f75d-f989-4e22-8e4c-24e11587800f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:29:11,741] Trial 0 finished with value: 0.23345844059558737 and parameters: {'max_depth': 10, 'subsample': 0.5638741596147292, 'colsample_bytree': 0.7384131356696705, 'min_child_weight': 15, 'gamma': 0.5113229007547395, 'lambda': 0.8205025287770785, 'alpha': 0.0880136963471753}. Best is trial 0 with value: 0.23345844059558737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:29:32,819] Trial 1 finished with value: 0.28513695658373267 and parameters: {'max_depth': 19, 'subsample': 0.9193228225079946, 'colsample_bytree': 0.9400118466848117, 'min_child_weight': 49, 'gamma': 0.7741274183067095, 'lambda': 0.009786563763897235, 'alpha': 5.222866954426521e-05}. Best is trial 0 with value: 0.23345844059558737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:29:53,913] Trial 2 finished with value: 0.2098579046980519 and parameters: {'max_depth': 20, 'subsample': 0.6928104572408043, 'colsample_bytree': 0.6489636877972498, 'min_child_weight': 8, 'gamma': 0.27658035367214273, 'lambda': 0.05974554894901843, 'alpha': 1.1206535418752302e-05}. Best is trial 2 with value: 0.2098579046980519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:30:15,029] Trial 3 finished with value: 0.21940865755874223 and parameters: {'max_depth': 12, 'subsample': 0.7609504534353893, 'colsample_bytree': 0.72853191765251, 'min_child_weight': 13, 'gamma': 0.9071821842308171, 'lambda': 0.31871678346386884, 'alpha': 0.00033719254321316916}. Best is trial 2 with value: 0.2098579046980519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:30:35,831] Trial 4 finished with value: 0.2520797918491998 and parameters: {'max_depth': 16, 'subsample': 0.7856446787942051, 'colsample_bytree': 0.6048182915192853, 'min_child_weight': 28, 'gamma': 0.07164853843563146, 'lambda': 0.0020927923496890685, 'alpha': 0.19043611956286327}. Best is trial 2 with value: 0.2098579046980519.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:30:56,661] Trial 5 finished with value: 0.2065449683424389 and parameters: {'max_depth': 19, 'subsample': 0.802694519994612, 'colsample_bytree': 0.8239438223530915, 'min_child_weight': 10, 'gamma': 0.15064723316780282, 'lambda': 1.7537939281699167e-05, 'alpha': 0.0018823083868408606}. Best is trial 5 with value: 0.2065449683424389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:31:18,831] Trial 6 finished with value: 0.1945140033182595 and parameters: {'max_depth': 11, 'subsample': 0.88498639452533, 'colsample_bytree': 0.9508417131342132, 'min_child_weight': 5, 'gamma': 0.5275941377044671, 'lambda': 0.00033146983684891913, 'alpha': 4.349401044279734e-05}. Best is trial 6 with value: 0.1945140033182595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:31:39,666] Trial 7 finished with value: 0.2566511318906418 and parameters: {'max_depth': 19, 'subsample': 0.7700617217716972, 'colsample_bytree': 0.8385429027851542, 'min_child_weight': 30, 'gamma': 0.610396130402024, 'lambda': 0.020539258585357618, 'alpha': 0.20758402103258805}. Best is trial 6 with value: 0.1945140033182595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:32:00,773] Trial 8 finished with value: 0.2436603280063469 and parameters: {'max_depth': 10, 'subsample': 0.8488232531139435, 'colsample_bytree': 0.6104446893585643, 'min_child_weight': 26, 'gamma': 0.57137527030976, 'lambda': 0.00017361252031892018, 'alpha': 9.886673568721823e-05}. Best is trial 6 with value: 0.1945140033182595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:32:22,242] Trial 9 finished with value: 0.21975231700563178 and parameters: {'max_depth': 12, 'subsample': 0.797971131045615, 'colsample_bytree': 0.7409712244935688, 'min_child_weight': 11, 'gamma': 0.9430927959794426, 'lambda': 0.02624587453904416, 'alpha': 0.009339548847515053}. Best is trial 6 with value: 0.1945140033182595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:32:43,450] Trial 10 finished with value: 0.2656730091931675 and parameters: {'max_depth': 15, 'subsample': 0.9953760167149567, 'colsample_bytree': 0.9961874177704162, 'min_child_weight': 42, 'gamma': 0.38933138427640657, 'lambda': 0.0007964145858414735, 'alpha': 1.0043041341387387e-05}. Best is trial 6 with value: 0.1945140033182595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:33:04,989] Trial 11 finished with value: 0.19229255960518107 and parameters: {'max_depth': 16, 'subsample': 0.8949049484677084, 'colsample_bytree': 0.8777650409099615, 'min_child_weight': 1, 'gamma': 0.05702402144178115, 'lambda': 1.2930776116257867e-05, 'alpha': 0.0013674745684111261}. Best is trial 11 with value: 0.19229255960518107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:33:26,722] Trial 12 finished with value: 0.19500020312992 and parameters: {'max_depth': 16, 'subsample': 0.9175146783596371, 'colsample_bytree': 0.8968060010758319, 'min_child_weight': 1, 'gamma': 0.2314555343832728, 'lambda': 2.8866941913615512e-05, 'alpha': 0.0009627998246410067}. Best is trial 11 with value: 0.19229255960518107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:33:48,587] Trial 13 finished with value: 0.192581660798051 and parameters: {'max_depth': 14, 'subsample': 0.8903622845466986, 'colsample_bytree': 0.8939028319111513, 'min_child_weight': 1, 'gamma': 0.01788785942077562, 'lambda': 0.00011611488276408512, 'alpha': 0.010454734393269029}. Best is trial 11 with value: 0.19229255960518107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:34:09,655] Trial 14 finished with value: 0.2186933185901782 and parameters: {'max_depth': 14, 'subsample': 0.9942101569424184, 'colsample_bytree': 0.8635090215565896, 'min_child_weight': 17, 'gamma': 0.03444184326025633, 'lambda': 1.1168212424929067e-05, 'alpha': 0.005944289877037032}. Best is trial 11 with value: 0.19229255960518107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:34:31,034] Trial 15 finished with value: 0.1888898037875895 and parameters: {'max_depth': 14, 'subsample': 0.8580569207495703, 'colsample_bytree': 0.8675107869104106, 'min_child_weight': 1, 'gamma': 0.0342216711897765, 'lambda': 8.92198348856514e-05, 'alpha': 0.02192966393799735}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:34:52,304] Trial 16 finished with value: 0.23532190927864796 and parameters: {'max_depth': 17, 'subsample': 0.6722258209091821, 'colsample_bytree': 0.7914036622153816, 'min_child_weight': 18, 'gamma': 0.16844126281876665, 'lambda': 7.545370041810856e-05, 'alpha': 0.03157972000175719}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:35:13,200] Trial 17 finished with value: 0.26343938535670974 and parameters: {'max_depth': 13, 'subsample': 0.84110179499935, 'colsample_bytree': 0.8816665467400105, 'min_child_weight': 35, 'gamma': 0.337147346861665, 'lambda': 4.7225873265638725e-05, 'alpha': 0.7138053963663563}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:35:34,127] Trial 18 finished with value: 0.22785196588806428 and parameters: {'max_depth': 17, 'subsample': 0.9365657848328598, 'colsample_bytree': 0.79514610556395, 'min_child_weight': 20, 'gamma': 0.11776458523823496, 'lambda': 0.00032981077150292084, 'alpha': 0.0020738571511946468}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:35:55,135] Trial 19 finished with value: 0.19550704730149074 and parameters: {'max_depth': 15, 'subsample': 0.8497281564525394, 'colsample_bytree': 0.9182703589593617, 'min_child_weight': 5, 'gamma': 0.22034599776720068, 'lambda': 1.2742131632352016e-05, 'alpha': 0.02090152548865444}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:36:16,020] Trial 20 finished with value: 0.23270880099783917 and parameters: {'max_depth': 17, 'subsample': 0.9545094064249177, 'colsample_bytree': 0.8486909414873707, 'min_child_weight': 22, 'gamma': 0.021442230949898833, 'lambda': 4.177162559719979e-05, 'alpha': 0.0007105854937332897}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:36:37,292] Trial 21 finished with value: 0.19235702500609753 and parameters: {'max_depth': 14, 'subsample': 0.8931695538846202, 'colsample_bytree': 0.8928816446829836, 'min_child_weight': 1, 'gamma': 0.005447104577598089, 'lambda': 0.00010411702099661491, 'alpha': 0.004746162770476865}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:36:58,287] Trial 22 finished with value: 0.1925406277706714 and parameters: {'max_depth': 14, 'subsample': 0.8829638324797342, 'colsample_bytree': 0.8710580489866044, 'min_child_weight': 5, 'gamma': 0.13119886841624967, 'lambda': 6.695925681777704e-05, 'alpha': 0.004671632469490427}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:37:19,317] Trial 23 finished with value: 0.19119828913511044 and parameters: {'max_depth': 13, 'subsample': 0.9493394894334929, 'colsample_bytree': 0.9238736460772325, 'min_child_weight': 1, 'gamma': 0.0012494361083969395, 'lambda': 1.0669130341234717e-05, 'alpha': 0.004084917345026427}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:37:40,176] Trial 24 finished with value: 0.1999570792335989 and parameters: {'max_depth': 13, 'subsample': 0.9588627898330702, 'colsample_bytree': 0.9410978447187085, 'min_child_weight': 8, 'gamma': 0.09554773731473437, 'lambda': 1.1035407853225641e-05, 'alpha': 0.02336761968963713}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:38:01,001] Trial 25 finished with value: 0.19834750866515055 and parameters: {'max_depth': 12, 'subsample': 0.9596621762325476, 'colsample_bytree': 0.9834870657558987, 'min_child_weight': 6, 'gamma': 0.1900275540358487, 'lambda': 2.3709825433385274e-05, 'alpha': 0.002411808664938033}. Best is trial 15 with value: 0.1888898037875895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:38:22,140] Trial 26 finished with value: 0.18852101853016237 and parameters: {'max_depth': 15, 'subsample': 0.8238162287701074, 'colsample_bytree': 0.9228279600494155, 'min_child_weight': 1, 'gamma': 0.09230930171966377, 'lambda': 3.038297036589117e-05, 'alpha': 0.0005601089554762329}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:38:42,865] Trial 27 finished with value: 0.2144083130097973 and parameters: {'max_depth': 13, 'subsample': 0.8280626603536048, 'colsample_bytree': 0.9703961841917291, 'min_child_weight': 13, 'gamma': 0.2922227152736946, 'lambda': 3.200520788480571e-05, 'alpha': 0.00040902587439230854}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:39:03,484] Trial 28 finished with value: 0.27115933636901907 and parameters: {'max_depth': 15, 'subsample': 0.7327826980355548, 'colsample_bytree': 0.9184989859563675, 'min_child_weight': 35, 'gamma': 0.11100573221849508, 'lambda': 0.00021505886151559428, 'alpha': 0.0031799102876066045}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:39:24,192] Trial 29 finished with value: 0.2286869876598432 and parameters: {'max_depth': 11, 'subsample': 0.5790292508013615, 'colsample_bytree': 0.9131767393059559, 'min_child_weight': 15, 'gamma': 0.39608093367798936, 'lambda': 6.213163270007742e-05, 'alpha': 0.05239985877850919}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:39:45,055] Trial 30 finished with value: 0.19098401627135325 and parameters: {'max_depth': 11, 'subsample': 0.8653820170939746, 'colsample_bytree': 0.9611557582965226, 'min_child_weight': 4, 'gamma': 0.0029982275008976884, 'lambda': 0.0006067798049603243, 'alpha': 0.011586621321913074}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:40:07,792] Trial 31 finished with value: 0.19137666397394057 and parameters: {'max_depth': 10, 'subsample': 0.8575063602700839, 'colsample_bytree': 0.9615957764058629, 'min_child_weight': 4, 'gamma': 0.0023242227831475537, 'lambda': 0.0007033438764332172, 'alpha': 0.012520359242686156}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:40:29,838] Trial 32 finished with value: 0.20846774950529628 and parameters: {'max_depth': 11, 'subsample': 0.8235052771503978, 'colsample_bytree': 0.9374058956855542, 'min_child_weight': 10, 'gamma': 0.07982581714406276, 'lambda': 2.8823731703828883e-05, 'alpha': 0.04901079845552225}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:40:50,976] Trial 33 finished with value: 0.2043442055892378 and parameters: {'max_depth': 13, 'subsample': 0.9206388319623376, 'colsample_bytree': 0.9709737145044076, 'min_child_weight': 8, 'gamma': 0.15354619214680584, 'lambda': 0.00012095852103885512, 'alpha': 0.01303953244384725}. Best is trial 26 with value: 0.18852101853016237.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:41:12,135] Trial 34 finished with value: 0.1869346261126617 and parameters: {'max_depth': 12, 'subsample': 0.8156147372037363, 'colsample_bytree': 0.929281034485093, 'min_child_weight': 3, 'gamma': 0.07615287148781857, 'lambda': 4.7847669577901836e-05, 'alpha': 0.005324925042644037}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:41:33,553] Trial 35 finished with value: 0.1906377521024613 and parameters: {'max_depth': 12, 'subsample': 0.8150776341027932, 'colsample_bytree': 0.998929745083561, 'min_child_weight': 4, 'gamma': 0.20405269818446647, 'lambda': 0.0034773904964175853, 'alpha': 0.005856687301603068}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:41:54,604] Trial 36 finished with value: 0.20502620708761352 and parameters: {'max_depth': 12, 'subsample': 0.815465596520198, 'colsample_bytree': 0.9889233981465734, 'min_child_weight': 8, 'gamma': 0.23780735737105171, 'lambda': 0.00322960894535774, 'alpha': 0.001147226609615079}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:42:15,464] Trial 37 finished with value: 0.21695621802401685 and parameters: {'max_depth': 15, 'subsample': 0.7862688795128868, 'colsample_bytree': 0.9396464059671631, 'min_child_weight': 14, 'gamma': 0.08096240639906473, 'lambda': 0.002444325019440806, 'alpha': 0.0005698790466275194}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:42:36,860] Trial 38 finished with value: 0.18967888835919683 and parameters: {'max_depth': 18, 'subsample': 0.7443303005990227, 'colsample_bytree': 0.9938523164054209, 'min_child_weight': 3, 'gamma': 0.1542193161687215, 'lambda': 0.004917957996851772, 'alpha': 0.00022760807542340992}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:42:57,722] Trial 39 finished with value: 0.29473816190759056 and parameters: {'max_depth': 20, 'subsample': 0.7776120188223626, 'colsample_bytree': 0.9523785438240845, 'min_child_weight': 46, 'gamma': 0.164441647032056, 'lambda': 0.006190056604049792, 'alpha': 0.000191148901777247}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:43:18,898] Trial 40 finished with value: 0.21128992608335828 and parameters: {'max_depth': 18, 'subsample': 0.7448222807092826, 'colsample_bytree': 0.9272976846163015, 'min_child_weight': 11, 'gamma': 0.07694818422816957, 'lambda': 0.00134564409846585, 'alpha': 0.00023150060075425558}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:43:40,166] Trial 41 finished with value: 0.18871058089447895 and parameters: {'max_depth': 18, 'subsample': 0.8163351087040205, 'colsample_bytree': 0.9926023630359853, 'min_child_weight': 3, 'gamma': 0.1954598147584536, 'lambda': 0.006406812855636874, 'alpha': 0.0017366558774772876}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:44:01,412] Trial 42 finished with value: 0.1904601291586218 and parameters: {'max_depth': 18, 'subsample': 0.8034577625332616, 'colsample_bytree': 0.9854421198135623, 'min_child_weight': 3, 'gamma': 0.127326314497393, 'lambda': 0.005415485866735852, 'alpha': 0.0015526923402741028}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:44:22,504] Trial 43 finished with value: 0.20295802463292487 and parameters: {'max_depth': 18, 'subsample': 0.759425605712166, 'colsample_bytree': 0.9736246366270096, 'min_child_weight': 7, 'gamma': 0.1751326390897062, 'lambda': 0.009270402391679507, 'alpha': 0.0007003195138895791}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:44:43,289] Trial 44 finished with value: 0.20689963424040075 and parameters: {'max_depth': 19, 'subsample': 0.8308598003879362, 'colsample_bytree': 0.9580964846205968, 'min_child_weight': 11, 'gamma': 0.26203524940653083, 'lambda': 0.0163526575889587, 'alpha': 0.0003443181160237758}. Best is trial 34 with value: 0.1869346261126617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:45:04,365] Trial 45 finished with value: 0.18393312159401515 and parameters: {'max_depth': 16, 'subsample': 0.7964224471104304, 'colsample_bytree': 0.9980888519016159, 'min_child_weight': 3, 'gamma': 0.06240083389225054, 'lambda': 1.9100318498837533e-05, 'alpha': 7.549225411491589e-05}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:45:25,288] Trial 46 finished with value: 0.1992248599312627 and parameters: {'max_depth': 16, 'subsample': 0.8631572154580438, 'colsample_bytree': 0.9082802105110277, 'min_child_weight': 7, 'gamma': 0.06475280151410323, 'lambda': 2.189251678980802e-05, 'alpha': 8.152074560814245e-05}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:45:46,321] Trial 47 finished with value: 0.1856343759060166 and parameters: {'max_depth': 16, 'subsample': 0.7958079360064744, 'colsample_bytree': 0.937304653180782, 'min_child_weight': 3, 'gamma': 0.06493789239323447, 'lambda': 1.803029228694769e-05, 'alpha': 0.0023648714696783667}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:46:07,249] Trial 48 finished with value: 0.20744941098073827 and parameters: {'max_depth': 17, 'subsample': 0.7926908336438162, 'colsample_bytree': 0.9424294317309004, 'min_child_weight': 9, 'gamma': 0.09785935095414627, 'lambda': 2.0113750215727108e-05, 'alpha': 2.3235100078827607e-05}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:46:28,296] Trial 49 finished with value: 0.18744630681725738 and parameters: {'max_depth': 17, 'subsample': 0.8068599140294371, 'colsample_bytree': 0.9746886851531067, 'min_child_weight': 3, 'gamma': 0.057511266197434296, 'lambda': 3.489102829836607e-05, 'alpha': 0.0024999954603226737}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:46:48,941] Trial 50 finished with value: 0.24515874451903974 and parameters: {'max_depth': 16, 'subsample': 0.7691425192179246, 'colsample_bytree': 0.9558224883448804, 'min_child_weight': 24, 'gamma': 0.08122924354026059, 'lambda': 4.570173626410836e-05, 'alpha': 0.0029032999739464368}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:47:10,041] Trial 51 finished with value: 0.1885110356487251 and parameters: {'max_depth': 16, 'subsample': 0.8054187130400965, 'colsample_bytree': 0.9780580673427473, 'min_child_weight': 3, 'gamma': 0.12969477728734352, 'lambda': 1.963843971940949e-05, 'alpha': 0.0016816455096649444}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:47:31,163] Trial 52 finished with value: 0.1955654589094407 and parameters: {'max_depth': 16, 'subsample': 0.7931324277346925, 'colsample_bytree': 0.9762090243582165, 'min_child_weight': 6, 'gamma': 0.054101356333293285, 'lambda': 1.8534057301687042e-05, 'alpha': 0.0009789844556442038}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:47:52,160] Trial 53 finished with value: 0.18747900187984576 and parameters: {'max_depth': 15, 'subsample': 0.8383922090020494, 'colsample_bytree': 0.9386824833969722, 'min_child_weight': 3, 'gamma': 0.12837323429463363, 'lambda': 3.1631868067865476e-05, 'alpha': 0.0015093061812438062}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:48:13,247] Trial 54 finished with value: 0.1927339844409023 and parameters: {'max_depth': 17, 'subsample': 0.7733186926525812, 'colsample_bytree': 0.9724286529520938, 'min_child_weight': 3, 'gamma': 0.044979450109943184, 'lambda': 1.8149374824969926e-05, 'alpha': 0.0022730933663432525}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:48:34,071] Trial 55 finished with value: 0.2090710650965894 and parameters: {'max_depth': 16, 'subsample': 0.8077297287585569, 'colsample_bytree': 0.9007919640072333, 'min_child_weight': 12, 'gamma': 0.15847611746827758, 'lambda': 4.758636574901156e-05, 'alpha': 0.0013379793525932584}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 23:48:55,175] Trial 56 finished with value: 0.197262268498447 and parameters: {'max_depth': 17, 'subsample': 0.8470621736560745, 'colsample_bytree': 0.9993056649929823, 'min_child_weight': 6, 'gamma': 0.04371404343599584, 'lambda': 1.572820330613116e-05, 'alpha': 0.006675380349044234}. Best is trial 45 with value: 0.18393312159401515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(f'Best parameters: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c8cbb9-71a7-47bd-b184-43579955c401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
