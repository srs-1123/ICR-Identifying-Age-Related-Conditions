{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672cd7e5-7478-4b75-a4db-810476f06233",
   "metadata": {},
   "source": [
    "# tabpfn_xgboost_mskf.ipynb\n",
    "## 実験条件\n",
    "* 学習時にgreeks.csvのEpsilon使用, テストデータでは訓練データのEpsilonの最大値+1とする\n",
    "* 欠損値は中央値で補完\n",
    "* greeks.csvのAlphaを予測、予測後にA->0, (B, G, D)->1に変換\n",
    "* CVはMultilabelStratifiedKFoldで、Beta, Gamma, Deltaのクラス割合が同じになるように分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b8938-dc60-4a04-b7d3-d3b2ec25170c",
   "metadata": {},
   "source": [
    "## TabPFNのインストール\n",
    "### 事前にダウンロードするファイル: \n",
    "* TabPFN: <https://www.kaggle.com/datasets/carlmcbrideellis/tabpfn-019-whl>\n",
    "* MultilabelStratifiedKFold: <https://www.kaggle.com/datasets/tilii7/iterative-stratification-017>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d61f413-8b49-4e6f-b89d-491fbbb50abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KaggleNotebookではコメントアウトを外す\n",
    "# !pip install -q /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n",
    "# !mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/\n",
    "# !pip install -q /kaggle/input/iterative-stratification-017/iterative_stratification-0.1.7-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97f9a60a-4bfa-423b-b613-a372d4c63685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "# model\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "# import lightgbm as lgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "# over/under sampling\n",
    "from imblearn.over_sampling import SMOTE # SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif# Feature Selection\n",
    "# import category_encoders as encoders\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "# cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "# others\n",
    "from datetime import date, datetime\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# 環境を指定\n",
    "env = 'local'\n",
    "# env = 'kaggle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d4b8a-f3c7-4274-8f37-b40dd2fe7008",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "39222989-8739-458c-99c0-c4cff87d149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリの指定\n",
    "if env == 'local':\n",
    "    BASE_DIR = '../../data'\n",
    "elif env == 'kaggle':\n",
    "    BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions/'\n",
    "else:\n",
    "    raise ValueError(\"Invalid environment. Set env as 'local' or 'kaggle'.\")\n",
    "\n",
    "# データの読み込み\n",
    "train_df = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "# train_df = pd.read_csv(f'{BASE_DIR}/train_integerized.csv')\n",
    "greeks_df = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "test_df = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "submission_df = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n",
    "\n",
    "# greeksと結合\n",
    "train_df = pd.merge(train_df, greeks_df[['Id', 'Alpha', 'Epsilon']], on='Id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e192c07-7cc0-43b3-940a-795381b7d93c",
   "metadata": {},
   "source": [
    "greeksのAはClass0に、B, G, DはClass1に相当"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f050385-9970-4624-8654-8ed504030602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alpha\n",
       "A    509\n",
       "B     61\n",
       "G     29\n",
       "D     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeks_df.Alpha.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788c1eb-f369-4df1-980a-587c443c43c1",
   "metadata": {},
   "source": [
    "## Epsilonを特徴量に追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ba3e3b4b-c47c-499e-a6cf-0b1f42ad96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値以外の日付をグレゴリオ暦の序数形式（1年1月1日を1とし、1日ずつ増やしていく）に変換\n",
    "train_df.Epsilon[train_df.Epsilon != 'Unknown'] = train_df.Epsilon[train_df.Epsilon != 'Unknown']\\\n",
    "                                        .map(lambda x: datetime.strptime(x, '%m/%d/%Y').toordinal())\n",
    "# 欠損値をnp.nanに変換\n",
    "train_df.Epsilon[train_df.Epsilon == 'Unknown'] = np.nan\n",
    "\n",
    "# 訓練データを説明変数と目的変数に分割\n",
    "X_train = train_df.drop(['Id', 'EJ', 'Alpha', 'Class'], axis=1)\n",
    "y_train = train_df[['Class', 'Alpha']]\n",
    "\n",
    "# テストデータから数値データ以外を削除\n",
    "X_test = test_df.drop(['Id', 'EJ'], axis=1)\n",
    "\n",
    "# テストデータは訓練データの最大値+1とする\n",
    "X_test['Epsilon'] = train_df.Epsilon.max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c29971-dd6e-4f2c-8b4f-808901cbea86",
   "metadata": {},
   "source": [
    "## モデル、評価基準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebac07ef-bc76-468e-af4c-9270e567beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedEns(BaseEstimator):\n",
    "    def __init__(self, xgb_params):\n",
    "        #xgb.fitだとパラメータをdict:paramで渡せない…\n",
    "        self.models = [XGBClassifier(eta = xgb_params['eta'], gamma = xgb_params['gamma'], max_depth = xgb_params['max_depth'],\n",
    "                           min_child_weight = xgb_params['min_child_weight'], max_delta_step = xgb_params['max_delta_step'],\n",
    "                           subsample = xgb_params['subsample'], reg_lambda = xgb_params['reg_lambda'], reg_alpha = xgb_params['reg_alpha'],\n",
    "                           tree_method = 'gpu_hist'),\n",
    "                       TabPFNClassifier(N_ensemble_configurations=256,device='cuda:0')]\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        # self.imputer = KNNImputer(n_neighbors=50)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = classes\n",
    "        X = self.imputer.fit_transform(X)\n",
    "        for i, model in enumerate(self.models):\n",
    "            if i > 0:\n",
    "                 model.fit(X,y)\n",
    "            else:\n",
    "                model.fit(X,y) # 決定木ではweightを考慮するようコードを変更\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imputer.transform(X)\n",
    "        ps = np.stack([model.predict_proba(X) for model in self.models])\n",
    "        p = np.mean(ps,axis=0)\n",
    "        class_0_est_instances = p[:,0].sum()\n",
    "        others_est_instances = p[:,1:].sum()\n",
    "        # we reweight the probs, since the loss is also balanced like this\n",
    "        # our models out of the box optimize CE\n",
    "        # with these changes they optimize balanced CE\n",
    "        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n",
    "        new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "        return np.concatenate((new_p[:,:1],np.sum(new_p[:,1:],1,keepdims=True)), 1)\n",
    "\n",
    "\n",
    "# 評価基準\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb70065",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning by Optuna\n",
    "\n",
    "epsilonはDate型でそのまま突っ込めない。考えるのめんどうだったので削ってチューニングした。許して"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5604b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値処理\n",
    "missing = X_train.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "\n",
    "#中央値\n",
    "for k, v in missing.items():\n",
    "    X_train[k] = X_train[k].fillna(X_train[k].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cc35b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:15:34,663] A new study created in memory with name: no-name-a64bfcd2-4625-43b9-862f-ea63ffa55570\n",
      "[I 2023-08-06 16:15:39,999] Trial 0 finished with value: 17.269388197455342 and parameters: {'eta': 1.3821865346164523e-06, 'gamma': 1.634088873011572e-08, 'max_depth': 3, 'min_child_weight': 3.956753947072637e-07, 'max_delta_step': 1.268616650059361e-06, 'subsample': 0.3962838313863627, 'reg_lambda': 794.254809222582, 'reg_alpha': 146.8652451957414}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:15:46,496] Trial 1 finished with value: 17.269388197455342 and parameters: {'eta': 1.3413832548800603e-06, 'gamma': 1.5426100105652803e-06, 'max_depth': 4, 'min_child_weight': 0.06253859325599373, 'max_delta_step': 3.0120574036957072e-06, 'subsample': 0.3828308128884884, 'reg_lambda': 428.08671443895906, 'reg_alpha': 201.70390187555455}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:15:53,263] Trial 2 finished with value: 17.269388197455342 and parameters: {'eta': 5.007378967741152e-06, 'gamma': 0.004036401679741396, 'max_depth': 15, 'min_child_weight': 0.5368315195787738, 'max_delta_step': 0.005557952893783737, 'subsample': 0.2910917767722875, 'reg_lambda': 265.62106277573673, 'reg_alpha': 704.8768600178968}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:00,713] Trial 3 finished with value: 17.269388197455342 and parameters: {'eta': 0.05359369107377943, 'gamma': 0.002990973818729527, 'max_depth': 10, 'min_child_weight': 0.035578175048848915, 'max_delta_step': 0.1541631687036376, 'subsample': 0.6364243002293828, 'reg_lambda': 361.74910314497964, 'reg_alpha': 256.51186717948246}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:07,986] Trial 4 finished with value: 17.269388197455342 and parameters: {'eta': 0.00011817243453086208, 'gamma': 4.479412066573753e-05, 'max_depth': 18, 'min_child_weight': 0.06357105975172321, 'max_delta_step': 0.0787911302697919, 'subsample': 0.723090210614953, 'reg_lambda': 865.1948155735496, 'reg_alpha': 934.5693669239641}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:14,421] Trial 5 finished with value: 17.269388197455342 and parameters: {'eta': 0.0007115654271370854, 'gamma': 1.449873220463718e-08, 'max_depth': 13, 'min_child_weight': 0.1534762811575135, 'max_delta_step': 0.023045145558144436, 'subsample': 0.033135086374274536, 'reg_lambda': 406.08777032681996, 'reg_alpha': 677.1342935765473}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:20,053] Trial 6 finished with value: 17.269388197455342 and parameters: {'eta': 4.3204685745588117e-07, 'gamma': 0.04564929283986358, 'max_depth': 20, 'min_child_weight': 0.43208266352263325, 'max_delta_step': 0.16855459873473563, 'subsample': 0.24812552108774122, 'reg_lambda': 90.95088189727952, 'reg_alpha': 615.6952502270718}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:25,759] Trial 7 finished with value: 17.269388197455342 and parameters: {'eta': 3.9563936088715893e-07, 'gamma': 4.915389319314051e-07, 'max_depth': 16, 'min_child_weight': 3.66822607451583e-06, 'max_delta_step': 0.09757822980289467, 'subsample': 0.32694685661473943, 'reg_lambda': 89.567981536261, 'reg_alpha': 554.0451430263194}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:31,423] Trial 8 finished with value: 17.269388197455342 and parameters: {'eta': 0.0520212684066823, 'gamma': 0.004471486704761978, 'max_depth': 10, 'min_child_weight': 5.147536375567691e-05, 'max_delta_step': 0.001981515881860499, 'subsample': 0.9172975904865281, 'reg_lambda': 854.8419983825303, 'reg_alpha': 466.28289833570545}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:36,858] Trial 9 finished with value: 17.269388197455342 and parameters: {'eta': 0.00028160121507781973, 'gamma': 0.023964476807219953, 'max_depth': 6, 'min_child_weight': 0.2786702942761442, 'max_delta_step': 2.3741996908175674e-07, 'subsample': 0.08737377238520794, 'reg_lambda': 826.020063072466, 'reg_alpha': 470.37829125710385}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:42,531] Trial 10 finished with value: 17.269388197455342 and parameters: {'eta': 3.684761818667293e-08, 'gamma': 0.8206318269437507, 'max_depth': 1, 'min_child_weight': 1.2195064621597469e-08, 'max_delta_step': 1.6504951146990437e-08, 'subsample': 0.5056798178754933, 'reg_lambda': 698.711267441412, 'reg_alpha': 6.973296988316179}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:48,562] Trial 11 finished with value: 17.269388197455342 and parameters: {'eta': 1.041513763106382e-08, 'gamma': 1.5392385029739426e-08, 'max_depth': 2, 'min_child_weight': 0.0023999808632574194, 'max_delta_step': 6.220712583191139e-06, 'subsample': 0.4670398352863473, 'reg_lambda': 596.9154931074187, 'reg_alpha': 134.56765960522372}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:16:54,119] Trial 12 finished with value: 17.269388197455342 and parameters: {'eta': 4.146736275117942e-06, 'gamma': 9.496455958014762e-07, 'max_depth': 5, 'min_child_weight': 1.6419751151016587e-06, 'max_delta_step': 2.1289806791761544e-05, 'subsample': 0.4353565954323878, 'reg_lambda': 574.279180609958, 'reg_alpha': 257.0260423428191}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:02,107] Trial 13 finished with value: 17.269388197455342 and parameters: {'eta': 7.820004523801013e-06, 'gamma': 5.487129740146904e-07, 'max_depth': 6, 'min_child_weight': 0.0022112385929691854, 'max_delta_step': 4.375200187485765e-06, 'subsample': 0.1914171950043087, 'reg_lambda': 990.1515449256201, 'reg_alpha': 1.2028615770454678}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:07,728] Trial 14 finished with value: 17.269388197455342 and parameters: {'eta': 2.1652103897637463e-07, 'gamma': 1.2531403709949482e-05, 'max_depth': 4, 'min_child_weight': 4.313701579740761e-08, 'max_delta_step': 0.00016991689866384748, 'subsample': 0.36146363854837427, 'reg_lambda': 493.7793352441969, 'reg_alpha': 262.3741349324312}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:12,881] Trial 15 finished with value: 17.269388197455342 and parameters: {'eta': 2.0922668933226628e-05, 'gamma': 8.781613787090188e-08, 'max_depth': 8, 'min_child_weight': 0.0014239036021564246, 'max_delta_step': 3.499445339550405e-07, 'subsample': 0.18494491199068486, 'reg_lambda': 662.4721197676786, 'reg_alpha': 351.9786422549097}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:18,582] Trial 16 finished with value: 17.269388197455342 and parameters: {'eta': 6.763533114470915e-07, 'gamma': 3.7053945947450733e-06, 'max_depth': 3, 'min_child_weight': 9.870379204322577e-05, 'max_delta_step': 0.00019686432740371497, 'subsample': 0.573798221644009, 'reg_lambda': 724.1543660709726, 'reg_alpha': 146.31015439781163}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:24,306] Trial 17 finished with value: 17.269388197455342 and parameters: {'eta': 5.86944272534717e-08, 'gamma': 7.821842411432067e-08, 'max_depth': 8, 'min_child_weight': 2.0038143917287247e-07, 'max_delta_step': 8.823197633038701e-07, 'subsample': 0.39906440438662044, 'reg_lambda': 534.816508047167, 'reg_alpha': 119.20214059226022}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:30,037] Trial 18 finished with value: 17.269388197455342 and parameters: {'eta': 3.440054962745186e-05, 'gamma': 0.00012241175409473677, 'max_depth': 8, 'min_child_weight': 1.3516484168564953e-05, 'max_delta_step': 3.3192398445227316e-08, 'subsample': 0.13546417786578235, 'reg_lambda': 446.2679268353866, 'reg_alpha': 371.94724333405065}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 16:17:35,779] Trial 19 finished with value: 17.269388197455342 and parameters: {'eta': 1.316028470673865e-06, 'gamma': 9.398882182828203e-08, 'max_depth': 12, 'min_child_weight': 4.829016707774276e-07, 'max_delta_step': 2.8282564687428658e-05, 'subsample': 0.274595216278244, 'reg_lambda': 273.45602388953273, 'reg_alpha': 102.36716925844365}. Best is trial 0 with value: 17.269388197455342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.269388197455342\n",
      "XGB tuned parameters\n",
      "{'eta': 1.3821865346164523e-06, 'gamma': 1.634088873011572e-08, 'max_depth': 3, 'min_child_weight': 3.956753947072637e-07, 'max_delta_step': 1.268616650059361e-06, 'subsample': 0.3962838313863627, 'reg_lambda': 794.254809222582, 'reg_alpha': 146.8652451957414}\n"
     ]
    }
   ],
   "source": [
    "# optunaでハイパーパラメータ選定\n",
    "\n",
    "def objective(trial):\n",
    "    eta =  trial.suggest_loguniform('eta', 1e-8, 1.0)\n",
    "    gamma = trial.suggest_loguniform('gamma', 1e-8, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_child_weight = trial.suggest_loguniform('min_child_weight', 1e-8, 1.0)\n",
    "    max_delta_step = trial.suggest_loguniform('max_delta_step', 1e-8, 1.0)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_uniform('reg_lambda', 0.0, 1000.0)\n",
    "    reg_alpha = trial.suggest_uniform('reg_alpha', 0.0, 1000.0)\n",
    "    tree_method = 'gpu_hist'\n",
    "\n",
    "\n",
    "    regr = XGBClassifier(eta = eta, gamma = gamma, max_depth = max_depth,\n",
    "                           min_child_weight = min_child_weight, max_delta_step = max_delta_step,\n",
    "                           subsample = subsample,reg_lambda = reg_lambda,reg_alpha = reg_alpha,\n",
    "                           tree_method=tree_method)\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    labels = greeks_df[['Beta', 'Gamma', 'Delta']] # クロスバリデーションの分割で考慮する特徴量\n",
    "    scores = []\n",
    "    for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, labels)):\n",
    "        # 進行状況\n",
    "        # print('fold: {}'.format(fold+1))\n",
    "        # 訓練データを分割\n",
    "        X_train_fold = X_train.iloc[train_index].drop(['Epsilon'], axis=1)\n",
    "        y_train_fold = y_train['Alpha'].iloc[train_index]\n",
    "        X_valid_fold = X_train.iloc[valid_index].drop(['Epsilon'], axis=1)\n",
    "        y_valid_fold = y_train['Class'].iloc[valid_index]\n",
    "        classes, y_train_unique = np.unique(y_train_fold, return_inverse=True)\n",
    "        regr.fit(X_train_fold, y_train_unique)\n",
    "\n",
    "        # imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        # X_valid_imputed = imputer.transform(X_valid_fold)\n",
    "        valid_preds = regr.predict(X_valid_fold)\n",
    "        # valid_proba = regr.predict_proba(X_valid_imputed)\n",
    "        # valid_ploba = np.mean(valid_proba)\n",
    "        # class_0_est_instances = valid_proba[:,0].sum()\n",
    "        # others_est_instances = valid_proba[:,1:].sum()\n",
    "        \n",
    "        # print('y_valid')\n",
    "        # print(y_valid_fold)\n",
    "        # print('-----------------------------')\n",
    "        # print('preds')\n",
    "        # print(valid_preds)\n",
    "        # exit(0)\n",
    "\n",
    "        score = balanced_log_loss(y_valid_fold, valid_preds)\n",
    "        scores.append(score)\n",
    "    mean = np.array(scores).mean()\n",
    "    print(mean)\n",
    "\n",
    "    return mean\n",
    "    \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print('XGB tuned parameters')\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c8c06-a9a1-47c7-b2bf-0b697cf7ccd9",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cf0b57b6-587b-44d0-a6af-76e9e7828b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 2\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 3\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 4\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 5\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 6\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 7\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 8\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 9\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 10\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "our out of folds CV score is 0.43883529491849294\n"
     ]
    }
   ],
   "source": [
    "# 初期値\n",
    "seed = 779292\n",
    "folds = 10\n",
    "labels = greeks_df[['Beta', 'Gamma', 'Delta']] # クロスバリデーションの分割で考慮する特徴量\n",
    "\n",
    "# 各分割ごとのバリデーションスコアを格納\n",
    "scores = 0\n",
    "# モデルを保存\n",
    "models = []\n",
    "# クロスバリデーションの分割数を指定します\n",
    "mskf = MultilabelStratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, labels)):\n",
    "    # 進行状況\n",
    "    print('fold: {}'.format(fold+1))\n",
    "    # 訓練データを分割\n",
    "    X_train_fold = X_train.iloc[train_index]\n",
    "    y_train_fold = y_train['Alpha'].iloc[train_index]\n",
    "    X_valid_fold = X_train.iloc[valid_index]\n",
    "    y_valid_fold = y_train['Class'].iloc[valid_index]\n",
    "    \n",
    "    # モデルを訓練、予測を出力\n",
    "    model = WeightedEns(xgb_params=study.best_params)\n",
    "    model.fit(X_train_fold,y_train_fold)\n",
    "    valid_preds = model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "    # 評価\n",
    "    val_score = balanced_log_loss(y_valid_fold, valid_preds)\n",
    "    # スコアを保存\n",
    "    scores += val_score\n",
    "    # モデルを保存\n",
    "    models.append(model)\n",
    "    \n",
    "# クロスバリデーションの平均値を計算\n",
    "cv_score = scores /  folds\n",
    "print(f'our out of folds CV score is {cv_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c79577-272f-431c-8757-165002c1010d",
   "metadata": {},
   "source": [
    "## 提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b06790e-ee1e-4c24-9aad-d48062526734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用に値を変換\n",
    "if env == 'kaggle':\n",
    "    # 予測\n",
    "    # 各分割ごとのテストデータに対する予測値を格納\n",
    "    preds = np.zeros(len(X_test))\n",
    "    for i in range(len(models)):\n",
    "        # pred = models[i].predict(xgb.DMatrix(test_df.drop(['Id', 'EJ'], axis=1)), iteration_range=(0, models[i].best_iteration))\n",
    "        pred = models[i].predict(X_test)\n",
    "        preds += pred\n",
    "    test_pred = preds / folds\n",
    "\n",
    "    # 提出\n",
    "    submission = pd.DataFrame(columns = submission_df.columns)\n",
    "    submission['Id'] = test_df['Id']\n",
    "    submission['class_0'] = 1 - test_pred\n",
    "    submission['class_1'] = test_pred\n",
    "    submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
