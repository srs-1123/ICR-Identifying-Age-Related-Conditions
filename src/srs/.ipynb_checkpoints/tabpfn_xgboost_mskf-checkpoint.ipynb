{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672cd7e5-7478-4b75-a4db-810476f06233",
   "metadata": {},
   "source": [
    "# tabpfn_xgboost_mskf.ipynb\n",
    "## 実験条件\n",
    "* 学習時にgreeks.csvのEpsilon使用, テストデータでは訓練データのEpsilonの最大値+1とする\n",
    "* 欠損値は中央値で補完\n",
    "* greeks.csvのAlphaを予測、予測後にA->0, (B, G, D)->1に変換\n",
    "* CVはMultilabelStratifiedKFoldで、Beta, Gamma, Deltaのクラス割合が同じになるように分割\n",
    "### 結果\n",
    "* CV: 0.19097697170787517\n",
    "## 変更点(2023-08-05 20:59)\n",
    "* XGBClassifierのsample_weightを設定\n",
    "* sample_weightを計算するためにAlphaをラベルエンコーディング\n",
    "### 結果\n",
    "* CV: 0.18313566432976108\n",
    "## 変更点(2023-08-07 0:29)\n",
    "* XGBClassifierのパラメータをさらに細かく設定\n",
    "### 結果\n",
    "* CV: 0.1762083652384992"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b8938-dc60-4a04-b7d3-d3b2ec25170c",
   "metadata": {},
   "source": [
    "## TabPFNのインストール\n",
    "### 事前にダウンロードするファイル: \n",
    "* TabPFN: <https://www.kaggle.com/datasets/carlmcbrideellis/tabpfn-019-whl>\n",
    "* MultilabelStratifiedKFold: <https://www.kaggle.com/datasets/tilii7/iterative-stratification-017>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d61f413-8b49-4e6f-b89d-491fbbb50abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KaggleNotebookではコメントアウトを外す\n",
    "# !pip install -q /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n",
    "# !mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/\n",
    "# !pip install -q /kaggle/input/iterative-stratification-017/iterative_stratification-0.1.7-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f9a60a-4bfa-423b-b613-a372d4c63685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "# model\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import lightgbm as lgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "# over/under sampling\n",
    "from imblearn.over_sampling import SMOTE # SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif# Feature Selection\n",
    "import category_encoders as encoders\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "# cross validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "# others\n",
    "from datetime import date, datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# 環境を指定\n",
    "env = 'local'\n",
    "# env = 'kaggle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d4b8a-f3c7-4274-8f37-b40dd2fe7008",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39222989-8739-458c-99c0-c4cff87d149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリの指定\n",
    "if env == 'local':\n",
    "    BASE_DIR = '../../data'\n",
    "elif env == 'kaggle':\n",
    "    BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions/'\n",
    "else:\n",
    "    raise ValueError(\"Invalid environment. Set env as 'local' or 'kaggle'.\")\n",
    "\n",
    "# データの読み込み\n",
    "train_df = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "# train_df = pd.read_csv(f'{BASE_DIR}/train_integerized.csv')\n",
    "greeks_df = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "test_df = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "submission_df = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n",
    "\n",
    "# greeksと結合\n",
    "train_df = pd.merge(train_df, greeks_df[['Id', 'Alpha', 'Epsilon']], on='Id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e192c07-7cc0-43b3-940a-795381b7d93c",
   "metadata": {},
   "source": [
    "greeksのAはClass0に、B, G, DはClass1に相当"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f050385-9970-4624-8654-8ed504030602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alpha\n",
       "A    509\n",
       "B     61\n",
       "G     29\n",
       "D     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeks_df.Alpha.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788c1eb-f369-4df1-980a-587c443c43c1",
   "metadata": {},
   "source": [
    "## Epsilonを特徴量に追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba3e3b4b-c47c-499e-a6cf-0b1f42ad96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値以外の日付をグレゴリオ暦の序数形式（1年1月1日を1とし、1日ずつ増やしていく）に変換\n",
    "train_df.Epsilon[train_df.Epsilon != 'Unknown'] = train_df.Epsilon[train_df.Epsilon != 'Unknown']\\\n",
    "                                        .map(lambda x: datetime.strptime(x, '%m/%d/%Y').toordinal())\n",
    "# 欠損値をnp.nanに変換\n",
    "train_df.Epsilon[train_df.Epsilon == 'Unknown'] = np.nan\n",
    "\n",
    "# 訓練データを説明変数と目的変数に分割\n",
    "X_train = train_df.drop(['Id', 'EJ', 'Alpha', 'Class'], axis=1)\n",
    "y_train = train_df[['Class', 'Alpha']]\n",
    "\n",
    "# テストデータから数値データ以外を削除\n",
    "X_test = test_df.drop(['Id', 'EJ'], axis=1)\n",
    "\n",
    "# テストデータは訓練データの最大値+1とする\n",
    "X_test['Epsilon'] = train_df.Epsilon.max()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19307475-d571-443e-9464-bc470dedb377",
   "metadata": {},
   "source": [
    "## Alphaをラベルエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45fa65ec-8711-4b29-af4f-eab77e820be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# ラベルエンコーダを初期化\n",
    "le = LabelEncoder()\n",
    "# yを数値に変換\n",
    "y_train['Alpha'] = le.fit_transform(y_train['Alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c29971-dd6e-4f2c-8b4f-808901cbea86",
   "metadata": {},
   "source": [
    "## モデル、評価基準"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebac07ef-bc76-468e-af4c-9270e567beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定値\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 18, \n",
    "    'subsample': 0.5236088397410353, \n",
    "    'colsample_bytree': 0.9081020201822949, \n",
    "    'min_child_weight': 1, \n",
    "    'gamma': 0.018902786999403336, \n",
    "    'lambda': 0.002946024021403057, \n",
    "    'alpha': 0.21131772406300453\n",
    "}\n",
    "\n",
    "class WeightedEns(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.models = [\n",
    "            XGBClassifier(),\n",
    "            TabPFNClassifier(N_ensemble_configurations=256,device='cuda:0')\n",
    "        ]\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        # self.imputer = KNNImputer(n_neighbors=50)\n",
    "    \n",
    "    def fit(self, X, y, weights=None):\n",
    "        classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = classes\n",
    "        X = self.imputer.fit_transform(X)\n",
    "        for i, model in enumerate(self.models):\n",
    "            if isinstance(model, XGBClassifier):\n",
    "                model.set_params(**xgb_params)\n",
    "                model.fit(X, y, sample_weight=weights) # 決定木ではweightを考慮する\n",
    "            else:\n",
    "                model.fit(X,y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imputer.transform(X)\n",
    "        ps = np.stack([model.predict_proba(X) for model in self.models])\n",
    "        p = np.mean(ps,axis=0)\n",
    "        class_0_est_instances = p[:,0].sum()\n",
    "        others_est_instances = p[:,1:].sum()\n",
    "        # we reweight the probs, since the loss is also balanced like this\n",
    "        # our models out of the box optimize CE\n",
    "        # with these changes they optimize balanced CE\n",
    "        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n",
    "        new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "        return np.concatenate((new_p[:,:1],np.sum(new_p[:,1:],1,keepdims=True)), 1)\n",
    "\n",
    "# 評価基準\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c8c06-a9a1-47c7-b2bf-0b697cf7ccd9",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0b57b6-587b-44d0-a6af-76e9e7828b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 2\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 3\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 4\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 5\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 6\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 7\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 8\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 9\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 10\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "our out of folds CV score is 0.1762083652384992\n"
     ]
    }
   ],
   "source": [
    "# 初期値\n",
    "seed = 779292\n",
    "folds = 10\n",
    "labels = greeks_df[['Beta', 'Gamma', 'Delta']] # クロスバリデーションの分割で考慮する特徴量\n",
    "\n",
    "# 各分割ごとのバリデーションスコアを格納\n",
    "scores = 0\n",
    "# モデルを保存\n",
    "models = []\n",
    "# クロスバリデーションの分割数を指定\n",
    "mskf = MultilabelStratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, labels)):\n",
    "    # 進行状況\n",
    "    print('fold: {}'.format(fold+1))\n",
    "    # 訓練データを分割\n",
    "    X_train_fold = X_train.iloc[train_index]\n",
    "    y_train_fold = y_train['Alpha'].iloc[train_index]\n",
    "    X_valid_fold = X_train.iloc[valid_index]\n",
    "    y_valid_fold = y_train['Class'].iloc[valid_index]\n",
    "\n",
    "    # Alphaのラベルに重みづけをする\n",
    "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train_fold)\n",
    "    \n",
    "    # モデルを訓練、予測を出力\n",
    "    model = WeightedEns()\n",
    "    model.fit(X_train_fold,y_train_fold, weights=sample_weights)\n",
    "    valid_preds = model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "    # 評価\n",
    "    val_score = balanced_log_loss(y_valid_fold, valid_preds)\n",
    "    # スコアを保存\n",
    "    scores += val_score\n",
    "    # モデルを保存\n",
    "    models.append(model)\n",
    "    \n",
    "# クロスバリデーションの平均値を計算\n",
    "cv_score = scores /  folds\n",
    "print(f'our out of folds CV score is {cv_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c79577-272f-431c-8757-165002c1010d",
   "metadata": {},
   "source": [
    "## 提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b06790e-ee1e-4c24-9aad-d48062526734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用に値を変換\n",
    "if env == 'kaggle':\n",
    "    # 予測\n",
    "    # 各分割ごとのテストデータに対する予測値を格納\n",
    "    preds = np.zeros(len(X_test))\n",
    "    for i in range(len(models)):\n",
    "        # pred = models[i].predict(xgb.DMatrix(test_df.drop(['Id', 'EJ'], axis=1)), iteration_range=(0, models[i].best_iteration))\n",
    "        pred = models[i].predict(X_test)\n",
    "        preds += pred\n",
    "    test_pred = preds / folds\n",
    "\n",
    "    # 提出\n",
    "    submission = pd.DataFrame(columns = submission_df.columns)\n",
    "    submission['Id'] = test_df['Id']\n",
    "    submission['class_0'] = 1 - test_pred\n",
    "    submission['class_1'] = test_pred\n",
    "    submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
