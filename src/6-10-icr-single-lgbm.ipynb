{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-29T15:09:03.138491Z",
     "iopub.status.busy": "2023-05-29T15:09:03.138116Z",
     "iopub.status.idle": "2023-05-29T15:09:06.104476Z",
     "shell.execute_reply": "2023-05-29T15:09:06.103131Z",
     "shell.execute_reply.started": "2023-05-29T15:09:03.138460Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-29T15:09:06.108141Z",
     "iopub.status.busy": "2023-05-29T15:09:06.107314Z",
     "iopub.status.idle": "2023-05-29T15:09:06.168948Z",
     "shell.execute_reply": "2023-05-29T15:09:06.167762Z",
     "shell.execute_reply.started": "2023-05-29T15:09:06.108096Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions/'\n",
    "BASE_DIR = '../data'\n",
    "train = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "greeks = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "test = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "submission = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n",
    "\n",
    "# test_df[CFG.target_col] = -1\n",
    "# all_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欠損値は中央値で埋める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing = train.isnull().sum()\n",
    "missing = missing[missing>0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in missing.index:\n",
    "    train[idx] = train[idx].fillna(train[idx].mean())\n",
    "    test[idx] = test[idx].fillna(test[idx].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量の数を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Columns:  58\n"
     ]
    }
   ],
   "source": [
    "# 列名を取得\n",
    "cols = train.columns\n",
    "# 特徴量の列名のみ抽出\n",
    "feat_cols = cols[1:]\n",
    "# 数値データのみ抽出\n",
    "num_cols = train.select_dtypes(include=['float64']).columns\n",
    "# 列数をカウント\n",
    "print(\"No of Columns: \", len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価指標の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンペティションの評価指標\n",
    "def competition_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "# こっちはようわからん\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "    return balanced_log_loss/(N_0+N_1)\n",
    "\n",
    "# light-gbmの学習中に使用するための関数\n",
    "def lgb_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スケーリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルエンコーディング\n",
    "train[\"EJ\"] = train[\"EJ\"].map({'A':0, 'B':1})\n",
    "test[\"EJ\"] = test[\"EJ\"].map({'A':0, \"B\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>...</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>-0.572153</td>\n",
       "      <td>-0.170975</td>\n",
       "      <td>-0.261669</td>\n",
       "      <td>-0.237889</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-1.900558</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>-0.173502</td>\n",
       "      <td>-0.038354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162487</td>\n",
       "      <td>-0.035806</td>\n",
       "      <td>-0.250869</td>\n",
       "      <td>-0.940094</td>\n",
       "      <td>-0.410260</td>\n",
       "      <td>-0.655511</td>\n",
       "      <td>-0.948991</td>\n",
       "      <td>0.531241</td>\n",
       "      <td>-0.815752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>-0.709105</td>\n",
       "      <td>-1.097801</td>\n",
       "      <td>-0.261669</td>\n",
       "      <td>-0.028701</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-0.750457</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>0.678919</td>\n",
       "      <td>-0.104787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458281</td>\n",
       "      <td>-0.060566</td>\n",
       "      <td>0.113218</td>\n",
       "      <td>-1.145070</td>\n",
       "      <td>-0.410260</td>\n",
       "      <td>0.687893</td>\n",
       "      <td>-0.238862</td>\n",
       "      <td>-0.509218</td>\n",
       "      <td>1.304239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>-0.015212</td>\n",
       "      <td>-0.377169</td>\n",
       "      <td>-0.261669</td>\n",
       "      <td>-0.094845</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>0.465662</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>0.519453</td>\n",
       "      <td>-0.104787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198331</td>\n",
       "      <td>-0.051023</td>\n",
       "      <td>0.596934</td>\n",
       "      <td>1.637944</td>\n",
       "      <td>-0.299210</td>\n",
       "      <td>-0.051850</td>\n",
       "      <td>-0.351743</td>\n",
       "      <td>-0.424754</td>\n",
       "      <td>-0.808323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>-0.480851</td>\n",
       "      <td>0.138196</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.547477</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-0.729610</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>0.112088</td>\n",
       "      <td>-0.104787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>-0.060566</td>\n",
       "      <td>-0.105234</td>\n",
       "      <td>-0.219883</td>\n",
       "      <td>-0.342195</td>\n",
       "      <td>-0.650833</td>\n",
       "      <td>0.858232</td>\n",
       "      <td>1.101332</td>\n",
       "      <td>-0.812311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>-0.206946</td>\n",
       "      <td>0.100517</td>\n",
       "      <td>-0.261669</td>\n",
       "      <td>-0.356885</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-0.628845</td>\n",
       "      <td>-0.013229</td>\n",
       "      <td>-1.649292</td>\n",
       "      <td>1.445139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236971</td>\n",
       "      <td>0.896815</td>\n",
       "      <td>-0.230064</td>\n",
       "      <td>-0.432313</td>\n",
       "      <td>0.099920</td>\n",
       "      <td>-0.318309</td>\n",
       "      <td>1.409422</td>\n",
       "      <td>-0.395228</td>\n",
       "      <td>-0.818054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>fd3dafe738fd</td>\n",
       "      <td>-0.699975</td>\n",
       "      <td>-0.161828</td>\n",
       "      <td>0.040232</td>\n",
       "      <td>-0.422762</td>\n",
       "      <td>0.275215</td>\n",
       "      <td>-0.802577</td>\n",
       "      <td>0.040875</td>\n",
       "      <td>-0.464891</td>\n",
       "      <td>-0.080610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458281</td>\n",
       "      <td>-0.045332</td>\n",
       "      <td>-0.271674</td>\n",
       "      <td>-1.177680</td>\n",
       "      <td>0.593022</td>\n",
       "      <td>-0.340465</td>\n",
       "      <td>-0.694915</td>\n",
       "      <td>0.513497</td>\n",
       "      <td>1.304239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>fd895603f071</td>\n",
       "      <td>-0.088253</td>\n",
       "      <td>0.852755</td>\n",
       "      <td>-0.261669</td>\n",
       "      <td>0.108831</td>\n",
       "      <td>0.556117</td>\n",
       "      <td>0.170319</td>\n",
       "      <td>-0.082686</td>\n",
       "      <td>0.473063</td>\n",
       "      <td>-0.065661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417330</td>\n",
       "      <td>-0.045702</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>1.519617</td>\n",
       "      <td>2.535523</td>\n",
       "      <td>-0.599582</td>\n",
       "      <td>-0.186764</td>\n",
       "      <td>2.048314</td>\n",
       "      <td>-0.813328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>fd8ef6377f76</td>\n",
       "      <td>-0.106514</td>\n",
       "      <td>-0.453742</td>\n",
       "      <td>0.090140</td>\n",
       "      <td>0.235206</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>0.990330</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>1.113828</td>\n",
       "      <td>-0.104787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458281</td>\n",
       "      <td>-0.060566</td>\n",
       "      <td>-0.271674</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>-0.019561</td>\n",
       "      <td>-0.424307</td>\n",
       "      <td>-0.540129</td>\n",
       "      <td>1.903449</td>\n",
       "      <td>1.304239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>fe1942975e40</td>\n",
       "      <td>-0.243466</td>\n",
       "      <td>-0.973904</td>\n",
       "      <td>-0.261669</td>\n",
       "      <td>-0.219353</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>0.955584</td>\n",
       "      <td>-0.083417</td>\n",
       "      <td>-0.699741</td>\n",
       "      <td>-0.104787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333153</td>\n",
       "      <td>-0.054771</td>\n",
       "      <td>0.191237</td>\n",
       "      <td>0.387591</td>\n",
       "      <td>-0.410260</td>\n",
       "      <td>-0.657500</td>\n",
       "      <td>-0.646592</td>\n",
       "      <td>-0.370599</td>\n",
       "      <td>-0.809518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>ffcca4ded3bb</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>-0.360885</td>\n",
       "      <td>3.350987</td>\n",
       "      <td>1.048310</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-0.920714</td>\n",
       "      <td>0.135921</td>\n",
       "      <td>-1.649292</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458281</td>\n",
       "      <td>-0.047645</td>\n",
       "      <td>-0.209259</td>\n",
       "      <td>-0.706235</td>\n",
       "      <td>-0.410260</td>\n",
       "      <td>-0.404872</td>\n",
       "      <td>1.446419</td>\n",
       "      <td>1.773276</td>\n",
       "      <td>1.304239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id        AB        AF        AH        AM        AR        AX   \n",
       "0    000ff2bfdfe9 -0.572153 -0.170975 -0.261669 -0.237889 -0.189295 -1.900558  \\\n",
       "1    007255e47698 -0.709105 -1.097801 -0.261669 -0.028701 -0.189295 -0.750457   \n",
       "2    013f2bd269f5 -0.015212 -0.377169 -0.261669 -0.094845 -0.189295  0.465662   \n",
       "3    043ac50845d5 -0.480851  0.138196  0.012347  0.547477 -0.189295 -0.729610   \n",
       "4    044fb8a146ec -0.206946  0.100517 -0.261669 -0.356885 -0.189295 -0.628845   \n",
       "..            ...       ...       ...       ...       ...       ...       ...   \n",
       "612  fd3dafe738fd -0.699975 -0.161828  0.040232 -0.422762  0.275215 -0.802577   \n",
       "613  fd895603f071 -0.088253  0.852755 -0.261669  0.108831  0.556117  0.170319   \n",
       "614  fd8ef6377f76 -0.106514 -0.453742  0.090140  0.235206 -0.011673  0.990330   \n",
       "615  fe1942975e40 -0.243466 -0.973904 -0.261669 -0.219353 -0.189295  0.955584   \n",
       "616  ffcca4ded3bb  0.012178 -0.360885  3.350987  1.048310 -0.189295 -0.920714   \n",
       "\n",
       "           AY        AZ        BC  ...        FL        FR        FS   \n",
       "0   -0.083417 -0.173502 -0.038354  ...  0.162487 -0.035806 -0.250869  \\\n",
       "1   -0.083417  0.678919 -0.104787  ... -0.458281 -0.060566  0.113218   \n",
       "2   -0.083417  0.519453 -0.104787  ...  0.198331 -0.051023  0.596934   \n",
       "3   -0.083417  0.112088 -0.104787  ...  0.060027 -0.060566 -0.105234   \n",
       "4   -0.013229 -1.649292  1.445139  ...  0.236971  0.896815 -0.230064   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "612  0.040875 -0.464891 -0.080610  ... -0.458281 -0.045332 -0.271674   \n",
       "613 -0.082686  0.473063 -0.065661  ...  0.417330 -0.045702  0.003992   \n",
       "614 -0.083417  1.113828 -0.104787  ... -0.458281 -0.060566 -0.271674   \n",
       "615 -0.083417 -0.699741 -0.104787  ...  0.333153 -0.054771  0.191237   \n",
       "616  0.135921 -1.649292 -0.001602  ... -0.458281 -0.047645 -0.209259   \n",
       "\n",
       "           GB        GE        GF        GH        GI        GL  Class  \n",
       "0   -0.940094 -0.410260 -0.655511 -0.948991  0.531241 -0.815752      1  \n",
       "1   -1.145070 -0.410260  0.687893 -0.238862 -0.509218  1.304239      0  \n",
       "2    1.637944 -0.299210 -0.051850 -0.351743 -0.424754 -0.808323      0  \n",
       "3   -0.219883 -0.342195 -0.650833  0.858232  1.101332 -0.812311      0  \n",
       "4   -0.432313  0.099920 -0.318309  1.409422 -0.395228 -0.818054      1  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "612 -1.177680  0.593022 -0.340465 -0.694915  0.513497  1.304239      0  \n",
       "613  1.519617  2.535523 -0.599582 -0.186764  2.048314 -0.813328      0  \n",
       "614 -0.076400 -0.019561 -0.424307 -0.540129  1.903449  1.304239      0  \n",
       "615  0.387591 -0.410260 -0.657500 -0.646592 -0.370599 -0.809518      0  \n",
       "616 -0.706235 -0.410260 -0.404872  1.446419  1.773276  1.304239      0  \n",
       "\n",
       "[617 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# インスタンス生成\n",
    "scaler = StandardScaler()\n",
    "# 訓練データ、テストデータのコピー\n",
    "df, test_df = train.copy(), test.copy()\n",
    "# ラベルエンコーディングを行なったので改めて数値データの特徴量を取得\n",
    "new_num_cols = train.select_dtypes(include=['float64']).columns\n",
    "# 訓練データを標準化\n",
    "df[new_num_cols] = scaler.fit_transform(train[new_num_cols])\n",
    "# テストデータを標準化\n",
    "test_df[new_num_cols] = scaler.transform(test[new_num_cols])\n",
    "# データを確認\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスバリデーションの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス生成\n",
    "kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "# fold列を作成\n",
    "df['fold'] = -1\n",
    "# 訓練データを分割\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(df, greeks['Alpha'])):\n",
    "    df.loc[test_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バリデーションスコアを格納\n",
    "final_valid_predictions = {}\n",
    "# テストデータの予測値を格納\n",
    "final_test_predictions = []\n",
    "\n",
    "scores = []\n",
    "log_losses = []\n",
    "balanced_log_losses = []\n",
    "weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's balanced_log_loss: 1.87105e-06\n",
      "[2000]\tvalid_0's balanced_log_loss: 1.29887e-06\n",
      "[3000]\tvalid_0's balanced_log_loss: 1.25726e-06\n",
      "Fold: 0, log loss: 3.128396546438618e-06, balanced los loss: 1.2615104015289935e-06\n",
      "\n",
      "Log Loss\n",
      "[3.128396546438618e-06]\n",
      "3.128396546438618e-06 0.0\n",
      "\n",
      "Balanced Log Loss\n",
      "[1.2615104015289935e-06]\n",
      "1.2615104015289935e-06 0.0\n",
      "\n",
      "Weights\n",
      "[792700.558622399]\n",
      "[1000]\tvalid_0's balanced_log_loss: 1.99577e-06\n",
      "[2000]\tvalid_0's balanced_log_loss: 1.32705e-06\n",
      "Fold: 1, log loss: 3.2877968643957725e-06, balanced los loss: 1.3282807037220512e-06\n",
      "\n",
      "Log Loss\n",
      "[3.128396546438618e-06, 3.2877968643957725e-06]\n",
      "3.208096705417195e-06 7.970015897857716e-08\n",
      "\n",
      "Balanced Log Loss\n",
      "[1.2615104015289935e-06, 1.3282807037220512e-06]\n",
      "1.2948955526255224e-06 3.3385151096528824e-08\n",
      "\n",
      "Weights\n",
      "[792700.558622399, 752852.9151992067]\n",
      "[1000]\tvalid_0's balanced_log_loss: 2.14312e-06\n",
      "[2000]\tvalid_0's balanced_log_loss: 1.34355e-06\n",
      "[3000]\tvalid_0's balanced_log_loss: 1.29775e-06\n",
      "Fold: 2, log loss: 3.147131614661848e-06, balanced los loss: 1.2968824856002975e-06\n",
      "\n",
      "Log Loss\n",
      "[3.128396546438618e-06, 3.2877968643957725e-06, 3.147131614661848e-06]\n",
      "3.187775008498746e-06 7.113850077206853e-08\n",
      "\n",
      "Balanced Log Loss\n",
      "[1.2615104015289935e-06, 1.3282807037220512e-06, 1.2968824856002975e-06]\n",
      "1.2955578636171142e-06 2.727494920602431e-08\n",
      "\n",
      "Weights\n",
      "[792700.558622399, 752852.9151992067, 771079.8866538187]\n",
      "[1000]\tvalid_0's balanced_log_loss: 1.97531e-06\n",
      "[2000]\tvalid_0's balanced_log_loss: 1.33371e-06\n",
      "[3000]\tvalid_0's balanced_log_loss: 1.29169e-06\n",
      "Fold: 3, log loss: 3.1335980175876976e-06, balanced los loss: 1.2928635324006923e-06\n",
      "\n",
      "Log Loss\n",
      "[3.128396546438618e-06, 3.2877968643957725e-06, 3.147131614661848e-06, 3.1335980175876976e-06]\n",
      "3.1742307607709836e-06 6.59230965489802e-08\n",
      "\n",
      "Balanced Log Loss\n",
      "[1.2615104015289935e-06, 1.3282807037220512e-06, 1.2968824856002975e-06, 1.2928635324006923e-06]\n",
      "1.2948842808130087e-06 2.3649593696834715e-08\n",
      "\n",
      "Weights\n",
      "[792700.558622399, 752852.9151992067, 771079.8866538187, 773476.8403151723]\n",
      "[1000]\tvalid_0's balanced_log_loss: 1.95537e-06\n",
      "[2000]\tvalid_0's balanced_log_loss: 1.34885e-06\n",
      "[3000]\tvalid_0's balanced_log_loss: 1.30989e-06\n",
      "Fold: 4, log loss: 3.165236386718279e-06, balanced los loss: 1.3050609593018488e-06\n",
      "\n",
      "Log Loss\n",
      "[3.128396546438618e-06, 3.2877968643957725e-06, 3.147131614661848e-06, 3.1335980175876976e-06, 3.165236386718279e-06]\n",
      "3.172431885960443e-06 5.907306940747982e-08\n",
      "\n",
      "Balanced Log Loss\n",
      "[1.2615104015289935e-06, 1.3282807037220512e-06, 1.2968824856002975e-06, 1.2928635324006923e-06, 1.3050609593018488e-06]\n",
      "1.2969196165107768e-06 2.154096077780021e-08\n",
      "\n",
      "Weights\n",
      "[792700.558622399, 752852.9151992067, 771079.8866538187, 773476.8403151723, 766247.7318568757]\n"
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    train_df = df[df['fold'] != fold]\n",
    "    valid_df = df[df['fold'] != fold]\n",
    "    valid_ids = valid_df.Id.values.tolist()\n",
    "    \n",
    "    X_train, y_train = train_df.drop(['Id', 'Class', 'fold'], axis=1), train_df['Class']\n",
    "    X_valid, y_valid = valid_df.drop(['Id', 'Class', 'fold'], axis=1), valid_df['Class']\n",
    "    \n",
    "    lgb = LGBMClassifier(boosting_type='goss', \n",
    "                         learning_rate=0.06733232950390658, \n",
    "                         n_estimators = 50000, \n",
    "                         early_stopping_round = 300, random_state=42,\n",
    "                         subsample=0.6970532011679706,\n",
    "                         colsample_bytree=0.6055755840633003,\n",
    "                         class_weight='balanced',\n",
    "                         metric='none', is_unbalance=True, max_depth=8)\n",
    "    # 学習\n",
    "    lgb.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=1000, eval_metric=lgb_metric)\n",
    "    \n",
    "    # 検証データの予測\n",
    "    y_pred = lgb.predict_proba(X_valid)\n",
    "    \n",
    "    # テストデータの予測\n",
    "    preds_test = lgb.predict_proba(test_df.drop(['Id'], axis=1).values)\n",
    "    \n",
    "    # 検証データの予測結果を辞書に追加\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, y_pred)))\n",
    "    # テストデータの予測結果をリストに追加\n",
    "    final_test_predictions.append(preds_test)\n",
    "    \n",
    "    # loglossを計算（コンペで使用されてるやつ）\n",
    "    logloss = log_loss(y_valid, y_pred)\n",
    "    # balanced_loglossを計算（よくわからんやつ）\n",
    "    balanced_logloss = balanced_log_loss(y_valid, y_pred[:, 1])\n",
    "    # loglossをリストに追加\n",
    "    log_losses.append(logloss)\n",
    "    # balanced_log_lossをリストに追加\n",
    "    balanced_log_losses.append(balanced_logloss)\n",
    "    # weightsをリストに追加\n",
    "    weights.append(1/balanced_logloss)\n",
    "\n",
    "    # 進行状況をプリント\n",
    "    print(f\"Fold: {fold}, log loss: {logloss}, balanced los loss: {balanced_logloss}\")\n",
    "    print()\n",
    "    print(\"Log Loss\")\n",
    "    print(log_losses)\n",
    "    print(np.mean(log_losses), np.std(log_losses))\n",
    "    print()\n",
    "    print(\"Balanced Log Loss\")\n",
    "    print(balanced_log_losses)\n",
    "    print(np.mean(balanced_log_losses), np.std(balanced_log_losses))\n",
    "    print()\n",
    "    print(\"Weights\")\n",
    "    print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9505311, 0.0494689],\n",
       "       [0.9505311, 0.0494689],\n",
       "       [0.9505311, 0.0494689],\n",
       "       [0.9505311, 0.0494689],\n",
       "       [0.9505311, 0.0494689]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テストを格納する行列を作成\n",
    "test_preds = np.zeros((test_df.shape[0], 2))\n",
    "for i in range(5):\n",
    "    # 重みとして損失関数の逆数をかける\n",
    "    test_preds[:, 0] += weights[i] * final_test_predictions[i][:, 0]\n",
    "    test_preds[:, 1] += weights[i] * final_test_predictions[i][:, 1]\n",
    "# 最後に重みの合計で割る\n",
    "test_preds /= sum(weights)\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.950531</td>\n",
       "      <td>0.049469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.950531</td>\n",
       "      <td>0.049469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.950531</td>\n",
       "      <td>0.049469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.950531</td>\n",
       "      <td>0.049469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.950531</td>\n",
       "      <td>0.049469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.950531  0.049469\n",
       "1  010ebe33f668  0.950531  0.049469\n",
       "2  02fa521e1838  0.950531  0.049469\n",
       "3  040e15f562a2  0.950531  0.049469\n",
       "4  046e85c7cc7f  0.950531  0.049469"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = {}\n",
    "test_dict.update(dict(zip(test.Id.values.tolist(), test_preds)))\n",
    "submission = pd.DataFrame.from_dict(test_dict, orient=\"index\").reset_index()\n",
    "submission.columns = ['Id', 'class_0', 'class_1']\n",
    "\n",
    "submission.to_csv(r\"submission.csv\", index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
