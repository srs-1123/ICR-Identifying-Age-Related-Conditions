{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c565dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effab245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨­å®šå€¤\n",
    "class CFG:\n",
    "    # å¤‰æ›´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    n_folds = 5 # å…¬å·®æ¤œè¨¼ã®åˆ†å‰²æ•°(å¤šãã¦20)\n",
    "    n_trials = 20 # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®è©¦è¡Œå›æ•°(100)\n",
    "    device_type = \"cpu\"\n",
    "    # device_type = \"cuda\"\n",
    "    boosting_type = \"gbdt\"\n",
    "    # boosting_type = \"dart\"\n",
    "    \n",
    "    \n",
    "    # ãã®ä»–è¨­å®šå€¤\n",
    "    learning_rate = 0.01\n",
    "    seed = 3407 \n",
    "    target_col = 'Class'\n",
    "    num_boost_round = 50500\n",
    "    early_stopping_round = 300\n",
    "    verbose_eval = 0  # ã“ã®æ•°å­—ã‚’1ã«ã™ã‚‹ã¨å­¦ç¿’æ™‚ã®ã‚¹ã‚³ã‚¢æ¨ç§»ãŒã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è¡¨ç¤ºã•ã‚Œã‚‹\n",
    "    \n",
    "    # light-gbmè¨­å®šå€¤\n",
    "    lgb_params = {\n",
    "        'verbosity': -1, # å­¦ç¿’é€”ä¸­ã®æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹\n",
    "        \"lambda_l1\": 2,\n",
    "        \"lambda_l2\": 4,\n",
    "        \"num_leaves\": 5,\n",
    "        \"feature_fraction\": 0.50,\n",
    "        \"bagging_fraction\": 0.80,\n",
    "        \"min_child_samples\": 0,\n",
    "        \"boosting_type\": boosting_type,\n",
    "        \"device_type\": device_type,\n",
    "        \"objective\": \"binary\",\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        'seed': seed,\n",
    "        'n_jobs': -1, # -1ã§ã‚³ã‚¢æ•°ã‚’ãƒãƒƒã‚¯ã‚¹ã§ä½¿ã†\n",
    "        'is_unbalance':True, # ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã«Trueã«ã™ã‚‹\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5341650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "test_df[CFG.target_col] = -1\n",
    "submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "all_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f928f11",
   "metadata": {},
   "source": [
    "BC, CLã¯ã„ã‚‰ã‚“ã‹ã‚‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6800fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
    "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
    "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
    "       'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
    "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "categorical_features = ['EJ']\n",
    "features = numerical_features + categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8910afd9",
   "metadata": {},
   "source": [
    "### balanced loglossã®è¨ˆç®—ï¼ˆå­¦ç¿’ã§ä½¿ã†ï¼Ÿï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0721bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰å‡¦ç†\n",
    "def Preprocessing(input_df: pd.DataFrame)->pd.DataFrame:\n",
    "    output_df = input_df.copy()\n",
    "    output_df['EJ'] = input_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "    return output_df\n",
    "\n",
    "all_df = Preprocessing(all_df)\n",
    "\n",
    "train_df = all_df[all_df[CFG.target_col] != -1].copy()\n",
    "test_df = all_df[all_df[CFG.target_col] == -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5b023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©•ä¾¡åŸºæº–\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability ğ‘ is replaced with max(min(ğ‘,1âˆ’10âˆ’15),10âˆ’15)\n",
    "    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d4a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’lgbç”¨ã«å¤‰æ›\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’lgbç”¨ã«å¤‰æ›\n",
    "    # lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params = CFG.lgb_params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = CFG.num_boost_round,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = CFG.early_stopping_round,\n",
    "        verbose_eval = CFG.verbose_eval,\n",
    "        # å­¦ç¿’æ®µéšã§balanced_log_lossã‚’ä½¿ã†å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆå¤–ã™\n",
    "        # feval = lgb_metric,\n",
    "    )\n",
    "    \n",
    "    # äºˆæ¸¬\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73fe9131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training fold 1\n",
      "training fold 2\n",
      "training fold 3\n",
      "training fold 4\n",
      "training fold 5\n",
      "our out of folds CV score is 0.284627902958425\n"
     ]
    }
   ],
   "source": [
    "# å„åˆ†å‰²ã”ã¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬å€¤ã‚’æ ¼ç´\n",
    "preds = np.zeros(len(test_df.drop([\"Id\", \"Class\"], axis=1)))\n",
    "# å„åˆ†å‰²ã”ã¨ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ ¼ç´\n",
    "scores = 0\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "for fold, (train_index, valid_index) in enumerate(kfold.split(train_df, train_df[CFG.target_col])):\n",
    "    print('training fold {}'.format(fold + 1))\n",
    "    \n",
    "    x_train = train_df[features].iloc[train_index]\n",
    "    y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "    x_valid = train_df[features].iloc[valid_index]\n",
    "    y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "\n",
    "    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®é‡ã¿ã‚’è¨ˆç®—\n",
    "    # train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®é‡ã¿ã‚’è¨ˆç®—\n",
    "    # valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’lgbç”¨ã«å¤‰æ›\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’lgbç”¨ã«å¤‰æ›\n",
    "    # lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    \n",
    "    # å­¦ç¿’\n",
    "    model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "    # è©•ä¾¡\n",
    "    val_score = balanced_log_loss(y_valid, valid_pred)\n",
    "    # äºˆæ¸¬\n",
    "    pred = model.predict(test_df.drop([\"Id\", \"Class\"], axis=1))\n",
    "    \n",
    "    # äºˆæ¸¬ã‚’ä¿å­˜\n",
    "    preds += pred\n",
    "    # ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜\n",
    "    scores += val_score\n",
    "    \n",
    "test_pred = preds / CFG.n_folds\n",
    "cv_score = scores /  CFG.n_folds\n",
    "print(f'our out of folds CV score is {scores /  CFG.n_folds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97e2a0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.268132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.268132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.268132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.268132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.731868</td>\n",
       "      <td>0.268132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.731868  0.268132\n",
       "1  010ebe33f668  0.731868  0.268132\n",
       "2  02fa521e1838  0.731868  0.268132\n",
       "3  040e15f562a2  0.731868  0.268132\n",
       "4  046e85c7cc7f  0.731868  0.268132"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æå‡ºç”¨ã«å€¤ã‚’å¤‰æ›\n",
    "submission = pd.DataFrame(columns = submission_df.columns)\n",
    "submission['Id'] = test_df['Id']\n",
    "submission['class_0'] = 1 - test_pred\n",
    "submission['class_1'] = test_pred\n",
    "# submission.to_csv('submission.csv',index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
