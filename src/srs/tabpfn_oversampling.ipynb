{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672cd7e5-7478-4b75-a4db-810476f06233",
   "metadata": {},
   "source": [
    "* TabPFNã¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ï¼‰XGBoostã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã€‚\n",
    "* ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå¯¾æ•°æå¤±ã«ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«ç¢ºç‡ã‚’é‡ã¿ä»˜ã‘ã—ç›´ã™\n",
    "* æ¬ æå€¤ã¯ä¸­å¤®å€¤ã§è£œå®Œ\n",
    "* è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“åˆ—ã‚’ä½¿ç”¨, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“åˆ—+1ã¨ã™ã‚‹\n",
    "* greeks.Alphaã§æä¾›ã•ã‚Œã‚‹4ã¤ã®ã‚¯ãƒ©ã‚¹ã™ã¹ã¦ã‚’ä½¿ç”¨ã—ã€å¾Œè€…ã®3ã¤ã®ã‚¯ãƒ©ã‚¹ã«ã¤ã„ã¦ã¯ç¢ºç‡ã‚’é›†ç´„ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96012eb6-5957-4eac-99eb-246becce24ba",
   "metadata": {},
   "source": [
    "* <https://www.kaggle.com/code/vadimkamaev/postprocessin-ensemble>\n",
    "* <https://www.kaggle.com/code/aikhmelnytskyy/public-krni-pdi-with-two-additional-models>\n",
    "* <https://www.kaggle.com/code/maverickss26/lb-0-06-icr>\n",
    "* <https://www.kaggle.com/code/siddhvr/xgb-tabpfn-improved>\n",
    "* <https://www.kaggle.com/code/renatoreggiani/icr-bestpublicscore-add-xgb-lgbm>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b8938-dc60-4a04-b7d3-d3b2ec25170c",
   "metadata": {},
   "source": [
    "## TabPFNã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "* äº‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«: <https://www.kaggle.com/datasets/carlmcbrideellis/tabpfn-019-whl>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d61f413-8b49-4e6f-b89d-491fbbb50abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n",
    "# !mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f9a60a-4bfa-423b-b613-a372d4c63685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "# model\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from tabpfn import TabPFNClassifier\n",
    "# over/under sampling\n",
    "from imblearn.over_sampling import SMOTE # SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif# Feature Selection\n",
    "import category_encoders as encoders\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "# others\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from datetime import date, datetime\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# ç’°å¢ƒã‚’æŒ‡å®š\n",
    "env = 'local'\n",
    "# env = 'kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39222989-8739-458c-99c0-c4cff87d149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æŒ‡å®š\n",
    "if env == 'local':\n",
    "    BASE_DIR = '../../data'\n",
    "elif env == 'kaggle':\n",
    "    BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions/'\n",
    "else:\n",
    "    raise ValueError(\"Invalid environment. Set env as 'local' or 'kaggle'.\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\n",
    "train_df = pd.read_csv(f'{BASE_DIR}/train.csv')\n",
    "# train_df = pd.read_csv(f'{BASE_DIR}/train_integerized.csv')\n",
    "greeks_df = pd.read_csv(f'{BASE_DIR}/greeks.csv')\n",
    "test_df = pd.read_csv(f'{BASE_DIR}/test.csv')\n",
    "submission_df = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n",
    "\n",
    "# greeksã¨çµåˆ\n",
    "train_df = pd.merge(train_df, greeks_df[['Id', 'Alpha', 'Epsilon']], on='Id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3e3b4b-c47c-499e-a6cf-0b1f42ad96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¬ æå€¤ä»¥å¤–ã®æ—¥ä»˜ã‚’ã‚°ãƒ¬ã‚´ãƒªã‚ªæš¦ã®åºæ•°å½¢å¼ï¼ˆ1å¹´1æœˆ1æ—¥ã‚’1ã¨ã—ã€1æ—¥ãšã¤å¢—ã‚„ã—ã¦ã„ãï¼‰ã«å¤‰æ›\n",
    "train_df.Epsilon[train_df.Epsilon != 'Unknown'] = train_df.Epsilon[train_df.Epsilon != 'Unknown']\\\n",
    "                                        .map(lambda x: datetime.strptime(x, '%m/%d/%Y').toordinal())\n",
    "# æ¬ æå€¤ã‚’np.nanã«å¤‰æ›\n",
    "train_df.Epsilon[train_df.Epsilon == 'Unknown'] = np.nan\n",
    "\n",
    "# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’èª¬æ˜å¤‰æ•°ã¨ç›®çš„å¤‰æ•°ã«åˆ†å‰²\n",
    "X_train = train_df.drop(['Id', 'EJ', 'Alpha', 'Class'], axis=1)\n",
    "y_train = train_df[['Class', 'Alpha']]\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ•°å€¤ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã‚’å‰Šé™¤\n",
    "X_test = test_df.drop(['Id', 'EJ'], axis=1)\n",
    "\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§å€¤+1ã¨ã™ã‚‹\n",
    "X_test['Epsilon'] = train_df.Epsilon.max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebac07ef-bc76-468e-af4c-9270e567beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedEns(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.models = [XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n",
    "                       TabPFNClassifier(N_ensemble_configurations=256,device='cuda:0')]\n",
    "        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "        # self.imputer = KNNImputer(n_neighbors=50)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        classes, y = np.unique(y, return_inverse=True)\n",
    "        self.classes_ = classes\n",
    "        X = self.imputer.fit_transform(X)\n",
    "        for model in self.models:\n",
    "            model.fit(X,y)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = self.imputer.transform(X)\n",
    "        ps = np.stack([model.predict_proba(X) for model in self.models])\n",
    "        p = np.mean(ps,axis=0)\n",
    "        class_0_est_instances = p[:,0].sum()\n",
    "        others_est_instances = p[:,1:].sum()\n",
    "        # we reweight the probs, since the loss is also balanced like this\n",
    "        # our models out of the box optimize CE\n",
    "        # with these changes they optimize balanced CE\n",
    "        new_p = p * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(p.shape[1])]])\n",
    "        new_p = new_p / np.sum(new_p,axis=1,keepdims=1)\n",
    "        return np.concatenate((new_p[:,:1],np.sum(new_p[:,1:],1,keepdims=True)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "661983fb-2fe2-4055-8353-51216715a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©•ä¾¡åŸºæº–\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability ğ‘ is replaced with max(min(ğ‘,1âˆ’10âˆ’15),10âˆ’15)\n",
    "    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf0b57b6-587b-44d0-a6af-76e9e7828b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 2\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 3\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 4\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "fold: 5\n",
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n",
      "our out of folds CV score is 0.09393895471301907\n"
     ]
    }
   ],
   "source": [
    "# å„åˆ†å‰²ã”ã¨ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ ¼ç´\n",
    "scores = 0\n",
    "# ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜\n",
    "models = []\n",
    "# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†å‰²ã§è€ƒæ…®ã™ã‚‹ç‰¹å¾´é‡\n",
    "labels = greeks_df[['Beta', 'Gamma', 'Delta']]\n",
    "# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†å‰²æ•°ã‚’æŒ‡å®šã—ã¾ã™\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=779292)\n",
    "\n",
    "for fold, (train_index, valid_index) in enumerate(mskf.split(X_train, labels)):\n",
    "    # é€²è¡ŒçŠ¶æ³\n",
    "    print('fold: {}'.format(fold+1))\n",
    "    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²\n",
    "    X_train_fold = X_train.iloc[train_index]\n",
    "    y_train_fold = y_train['Alpha'].iloc[train_index]\n",
    "    X_valid_fold = X_train.iloc[valid_index]\n",
    "    y_valid_fold = y_train['Class'].iloc[valid_index]\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€äºˆæ¸¬ã‚’å‡ºåŠ›\n",
    "    model = WeightedEns()\n",
    "    model.fit(X_train_fold,y_train_fold)\n",
    "    valid_preds = model.predict_proba(X_valid_fold)[:, 1]\n",
    "\n",
    "    # å¾Œå‡¦ç†\n",
    "    boost = 2.7 # TRY DIFFERENT FACTORS WITH YOUR MODEL\n",
    "    odds = boost * valid_preds / (1-valid_preds)\n",
    "    valid_preds = odds / (1+odds)\n",
    "\n",
    "    # è©•ä¾¡\n",
    "    val_score = balanced_log_loss(y_valid_fold, valid_preds)\n",
    "    # ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜\n",
    "    scores += val_score\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜\n",
    "    models.append(model)\n",
    "    \n",
    "# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å¹³å‡å€¤ã‚’è¨ˆç®—\n",
    "cv_score = scores /  12\n",
    "print(f'our out of folds CV score is {cv_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b06790e-ee1e-4c24-9aad-d48062526734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æå‡ºç”¨ã«å€¤ã‚’å¤‰æ›\n",
    "if env == 'kaggle':\n",
    "    # äºˆæ¸¬\n",
    "    # å„åˆ†å‰²ã”ã¨ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬å€¤ã‚’æ ¼ç´\n",
    "    preds = np.zeros(len(X_test))\n",
    "    for i in range(len(models)):\n",
    "        # pred = models[i].predict(xgb.DMatrix(test_df.drop(['Id', 'EJ'], axis=1)), iteration_range=(0, models[i].best_iteration))\n",
    "        pred = models[i].predict(X_test)\n",
    "        preds += pred\n",
    "    test_pred = preds / 12\n",
    "\n",
    "    # æå‡º\n",
    "    submission = pd.DataFrame(columns = submission_df.columns)\n",
    "    submission['Id'] = test_df['Id']\n",
    "    submission['class_0'] = 1 - test_pred\n",
    "    submission['class_1'] = test_pred\n",
    "    submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
