{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nimport optuna\nimport warnings\nfrom tqdm import tqdm_notebook as tqdm\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.576408Z","iopub.execute_input":"2023-06-03T07:14:08.576819Z","iopub.status.idle":"2023-06-03T07:14:08.583818Z","shell.execute_reply.started":"2023-06-03T07:14:08.576790Z","shell.execute_reply":"2023-06-03T07:14:08.582853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 設定値\nclass CFG:\n    # 変更するパラメータ\n    n_folds = 5 # 公差検証の分割数(多くて20)\n    n_trials = 20 # ハイパーパラメータチューニングの試行回数(100)\n    device_type = \"cpu\"\n    # device_type = \"cuda\"\n    boosting_type = \"gbdt\"\n    # boosting_type = \"dart\"\n    \n    \n    # その他設定値\n    learning_rate = 0.01\n    seed = 3407 \n    target_col = 'Class'\n    num_boost_round = 50500\n    early_stopping_round = 300\n    verbose_eval = 0  # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n    \n    # light-gbm設定値\n    lgb_params = {\n        'verbosity': -1, # 学習途中の情報を表示するかどうか\n        \"lambda_l1\": 2,\n        \"lambda_l2\": 4,\n        \"num_leaves\": 5,\n        \"feature_fraction\": 0.50,\n        \"bagging_fraction\": 0.80,\n        \"min_child_samples\": 0,\n        \"boosting_type\": boosting_type,\n        \"device_type\": device_type,\n        \"objective\": \"binary\",\n        \"learning_rate\": learning_rate,\n        \"metric\": \"binary_logloss\",\n        'seed': seed,\n        'n_jobs': -1, # -1でコア数をマックスで使う\n        'is_unbalance':True, # 不均衡データの場合にTrueにする\n    }","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.606301Z","iopub.execute_input":"2023-06-03T07:14:08.606712Z","iopub.status.idle":"2023-06-03T07:14:08.620080Z","shell.execute_reply.started":"2023-06-03T07:14:08.606681Z","shell.execute_reply":"2023-06-03T07:14:08.618803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/icr-identify-age-related-conditions/'\n# BASE_DIR = '..'\ntrain_df = pd.read_csv(f'{BASE_DIR}/train.csv')\ngreeks_df = pd.read_csv(f'{BASE_DIR}/greeks.csv')\ntest_df = pd.read_csv(f'{BASE_DIR}/test.csv')\nsubmission_df = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n\ntest_df[CFG.target_col] = -1\nall_df = pd.concat([train_df, test_df])","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.623384Z","iopub.execute_input":"2023-06-03T07:14:08.623887Z","iopub.status.idle":"2023-06-03T07:14:08.665581Z","shell.execute_reply.started":"2023-06-03T07:14:08.623821Z","shell.execute_reply":"2023-06-03T07:14:08.664409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BC, CLはいらんかも","metadata":{}},{"cell_type":"code","source":"numerical_features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n       'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\ncategorical_features = ['EJ']\nfeatures = numerical_features + categorical_features","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.667668Z","iopub.execute_input":"2023-06-03T07:14:08.668031Z","iopub.status.idle":"2023-06-03T07:14:08.675276Z","shell.execute_reply.started":"2023-06-03T07:14:08.667999Z","shell.execute_reply":"2023-06-03T07:14:08.674170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### balanced loglossの計算（学習で使う？）","metadata":{}},{"cell_type":"code","source":"# 前処理\ndef Preprocessing(input_df: pd.DataFrame)->pd.DataFrame:\n    output_df = input_df.copy()\n    output_df['EJ'] = input_df['EJ'].replace({'A': 0, 'B': 1})\n    return output_df\n\nall_df = Preprocessing(all_df)\n\ntrain_df = all_df[all_df[CFG.target_col] != -1].copy()\ntest_df = all_df[all_df[CFG.target_col] == -1].copy()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.676934Z","iopub.execute_input":"2023-06-03T07:14:08.677298Z","iopub.status.idle":"2023-06-03T07:14:08.699582Z","shell.execute_reply.started":"2023-06-03T07:14:08.677268Z","shell.execute_reply":"2023-06-03T07:14:08.698646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 評価基準\ndef balanced_log_loss(y_true, y_pred):\n    N = len(y_true)\n\n    # Nc is the number of observations\n    N_1 = np.sum(y_true == 1, axis=0)\n    N_0 = np.sum(y_true == 0, axis=0)\n\n    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n\n    # balanced logarithmic loss\n    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n\n    return loss_numerator / 2","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.701792Z","iopub.execute_input":"2023-06-03T07:14:08.702117Z","iopub.status.idle":"2023-06-03T07:14:08.715250Z","shell.execute_reply.started":"2023-06-03T07:14:08.702090Z","shell.execute_reply":"2023-06-03T07:14:08.713718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n    # 訓練データをlgb用に変換\n    # lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n    # 検証データをlgb用に変換\n    # lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n\n    model = lgb.train(\n        params = CFG.lgb_params,\n        train_set = lgb_train,\n        num_boost_round = CFG.num_boost_round,\n        valid_sets = [lgb_train, lgb_valid],\n        early_stopping_rounds = CFG.early_stopping_round,\n        verbose_eval = CFG.verbose_eval,\n        # 学習段階でbalanced_log_lossを使う場合はコメントアウト外す\n        # feval = lgb_metric,\n    )\n    \n    # 予測\n    valid_pred = model.predict(x_valid)\n    return model, valid_pred","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:08.716594Z","iopub.execute_input":"2023-06-03T07:14:08.716945Z","iopub.status.idle":"2023-06-03T07:14:08.730503Z","shell.execute_reply.started":"2023-06-03T07:14:08.716916Z","shell.execute_reply":"2023-06-03T07:14:08.729306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 各分割ごとのテストデータに対する予測値を格納\npreds = np.zeros(len(test_df.drop([\"Id\", \"Class\"], axis=1)))\n# 各分割ごとのバリデーションスコアを格納\nscores = 0\n\nkfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\nfor fold, (train_index, valid_index) in enumerate(kfold.split(train_df, train_df[CFG.target_col])):\n    print('training fold {}'.format(fold + 1))\n    \n    x_train = train_df[features].iloc[train_index]\n    y_train = train_df[CFG.target_col].iloc[train_index]\n    x_valid = train_df[features].iloc[valid_index]\n    y_valid = train_df[CFG.target_col].iloc[valid_index]\n\n    # 訓練データの重みを計算\n    # train_w0, train_w1 = calc_log_loss_weight(y_train)\n    # 検証データの重みを計算\n    # valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n    # 訓練データをlgb用に変換\n    # lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n    # 検証データをlgb用に変換\n    # lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n    \n    # 学習\n    model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n    # 評価\n    val_score = balanced_log_loss(y_valid, valid_pred)\n    # 予測\n    pred = model.predict(test_df.drop([\"Id\", \"Class\"], axis=1))\n    \n    # 予測を保存\n    preds += pred\n    # スコアを保存\n    scores += val_score\n    \ntest_pred = preds / CFG.n_folds\ncv_score = scores /  CFG.n_folds\nprint(f'our out of folds CV score is {scores /  CFG.n_folds}')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-06-03T07:14:08.774185Z","iopub.execute_input":"2023-06-03T07:14:08.774629Z","iopub.status.idle":"2023-06-03T07:14:31.592833Z","shell.execute_reply.started":"2023-06-03T07:14:08.774592Z","shell.execute_reply":"2023-06-03T07:14:31.591642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 提出用に値を変換\nsubmission = pd.DataFrame(columns = submission_df.columns)\nsubmission['Id'] = test_df['Id']\nsubmission['class_0'] = 1 - test_pred\nsubmission['class_1'] = test_pred\nsubmission.to_csv('submission.csv',index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:14:31.594702Z","iopub.execute_input":"2023-06-03T07:14:31.595025Z","iopub.status.idle":"2023-06-03T07:14:31.623745Z","shell.execute_reply.started":"2023-06-03T07:14:31.594998Z","shell.execute_reply":"2023-06-03T07:14:31.622596Z"},"trusted":true},"execution_count":null,"outputs":[]}]}