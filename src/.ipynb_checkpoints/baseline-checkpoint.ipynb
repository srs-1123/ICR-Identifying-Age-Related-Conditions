{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c565dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import warnings\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effab245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 設定値\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mclass\u001b[39;49;00m \u001b[39mCFG\u001b[39;49;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[39m# 変更するパラメータ\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m     n_folds \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m \u001b[39m# 公差検証の分割数(多くて20)\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m     n_trials \u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m \u001b[39m# ハイパーパラメータチューニングの試行回数(100)\u001b[39;49;00m\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mCFG\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m verbose_eval \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# この数字を1にすると学習時のスコア推移がコマンドライン表示される\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# light-gbm設定値\u001b[39;00m\n\u001b[1;32m     21\u001b[0m lgb_params \u001b[39m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mverbosity\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m# 学習途中の情報を表示するかどうか\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlambda_l1\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mlambda_l1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1e-8\u001b[39m, \u001b[39m10.0\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     24\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlambda_l2\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mlambda_l2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1e-8\u001b[39m, \u001b[39m10.0\u001b[39m, log\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     25\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnum_leaves\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m\"\u001b[39m\u001b[39mnum_leaves\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m256\u001b[39m),\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfeature_fraction\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mfeature_fraction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m1.0\u001b[39m),\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbagging_fraction\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m\"\u001b[39m\u001b[39mbagging_fraction\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m1.0\u001b[39m),\n\u001b[1;32m     28\u001b[0m     \u001b[39m# \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmin_child_samples\u001b[39m\u001b[39m\"\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m\"\u001b[39m\u001b[39mmin_child_samples\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m100\u001b[39m),\n\u001b[1;32m     30\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mboosting_type\u001b[39m\u001b[39m\"\u001b[39m: CFG\u001b[39m.\u001b[39mboosting_type,\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdevice_type\u001b[39m\u001b[39m\"\u001b[39m: CFG\u001b[39m.\u001b[39mdevice_type,\n\u001b[1;32m     32\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m: CFG\u001b[39m.\u001b[39mlearning_rate,\n\u001b[1;32m     34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mbinary_logloss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m'\u001b[39m: CFG\u001b[39m.\u001b[39mseed,\n\u001b[1;32m     36\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_jobs\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m# -1でコア数をマックスで使う\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mis_unbalance\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m, \u001b[39m# 不均衡データの場合にTrueにする\u001b[39;00m\n\u001b[1;32m     38\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "# 設定値\n",
    "class CFG:\n",
    "    # 変更するパラメータ\n",
    "    n_folds = 5 # 公差検証の分割数(多くて20)\n",
    "    n_trials = 20 # ハイパーパラメータチューニングの試行回数(100)\n",
    "    device_type = \"cpu\"\n",
    "    # device_type = \"cuda\"\n",
    "    boosting_type = \"gbdt\"\n",
    "    # boosting_type = \"dart\"\n",
    "    \n",
    "    \n",
    "    # その他設定値\n",
    "    learning_rate = 0.01\n",
    "    seed = 3407 \n",
    "    target_col = 'Class'\n",
    "    num_boost_round = 50500\n",
    "    early_stopping_round = 300\n",
    "    verbose_eval = 0  # この数字を1にすると学習時のスコア推移がコマンドライン表示される\n",
    "    \n",
    "    # light-gbm設定値\n",
    "    lgb_params = {\n",
    "        'verbosity': -1, # 学習途中の情報を表示するかどうか\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        # \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"boosting_type\": CFG.boosting_type,\n",
    "        \"device_type\": CFG.device_type,\n",
    "        \"objective\": \"binary\",\n",
    "        \"learning_rate\": CFG.learning_rate,\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        'seed': CFG.seed,\n",
    "        'n_jobs': -1, # -1でコア数をマックスで使う\n",
    "        'is_unbalance':True, # 不均衡データの場合にTrueにする\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5341650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "test_df[CFG.target_col] = -1\n",
    "submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "all_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f928f11",
   "metadata": {},
   "source": [
    "BC, CLはいらんかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6800fb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
    "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
    "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
    "       'EB', 'EE', 'EG', 'EH', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
    "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "categorical_features = ['EJ']\n",
    "features = numerical_features + categorical_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8910afd9",
   "metadata": {},
   "source": [
    "### balanced loglossの計算（学習で使う？）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0721bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "def Preprocessing(input_df: pd.DataFrame)->pd.DataFrame:\n",
    "    output_df = input_df.copy()\n",
    "    output_df['EJ'] = input_df['EJ'].replace({'A': 0, 'B': 1})\n",
    "    return output_df\n",
    "\n",
    "all_df = Preprocessing(all_df)\n",
    "\n",
    "train_df = all_df[all_df[CFG.target_col] != -1].copy()\n",
    "test_df = all_df[all_df[CFG.target_col] == -1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5b023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 重み計算\\ndef calc_log_loss_weight(y_true):\\n    nc = np.bincount(y_true)\\n    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\\n    return w0, w1\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価基準\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N = len(y_true)\n",
    "\n",
    "    # Nc is the number of observations\n",
    "    N_1 = np.sum(y_true == 1, axis=0)\n",
    "    N_0 = np.sum(y_true == 0, axis=0)\n",
    "\n",
    "    # In order to avoid the extremes of the log function, each predicted probability 𝑝 is replaced with max(min(𝑝,1−10−15),10−15)\n",
    "    y_pred = np.maximum(np.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "    # balanced logarithmic loss\n",
    "    loss_numerator = - (1/N_0) * np.sum((1 - y_true) * np.log(1-y_pred)) - (1/N_1) * np.sum(y_true * np.log(y_pred))\n",
    "\n",
    "    return loss_numerator / 2\n",
    "\n",
    "\"\"\"\n",
    "# 重み計算\n",
    "def calc_log_loss_weight(y_true):\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features):\n",
    "    # 訓練データをlgb用に変換\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    # 検証データをlgb用に変換\n",
    "    # lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params = CFG.lgb_params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = CFG.num_boost_round,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = CFG.early_stopping_round,\n",
    "        verbose_eval = CFG.verbose_eval,\n",
    "        # 学習段階でbalanced_log_lossを使う場合はコメントアウト外す\n",
    "        # feval = lgb_metric,\n",
    "    )\n",
    "    \n",
    "    # 予測\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed)\n",
    "pbar = tqdm(enumerate(kfold.split(train_df, train_df[CFG.target_col])))\n",
    "for fold, (train_index, valid_index) in pbar:\n",
    "# for fold, (train_index, valid_index) in enumerate(kfold.split(train_df, train_df[CFG.target_col])):\n",
    "    # 現在の試行回数を出力\n",
    "    pbar.set_description(\"[train] trials {}\".format(trial.number+1))\n",
    "\n",
    "    x_train = train_df[features].iloc[train_index]\n",
    "    y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "    x_valid = train_df[features].iloc[valid_index]\n",
    "    y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "\n",
    "    # 訓練データの重みを計算\n",
    "    # train_w0, train_w1 = calc_log_loss_weight(y_train)\n",
    "    # 検証データの重みを計算\n",
    "    # valid_w0, valid_w1 = calc_log_loss_weight(y_valid)\n",
    "    # 訓練データをlgb用に変換\n",
    "    # lgb_train = lgb.Dataset(x_train, y_train, weight=y_train.map({0: train_w0, 1: train_w1}), categorical_feature=categorical_features)\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    # 検証データをlgb用に変換\n",
    "    # lgb_valid = lgb.Dataset(x_valid, y_valid, weight=y_valid.map({0: valid_w0, 1: valid_w1}), categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    \n",
    "    # 学習\n",
    "    model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "    val_score = balanced_log_loss(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'verbosity': -1, # 学習途中の情報を表示するかどうか\n",
    "    \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "    \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "    \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "    \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 1.0),\n",
    "    \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "    # \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    \"boosting_type\": CFG.boosting_type,\n",
    "    \"device_type\": CFG.device_type,\n",
    "    \"objective\": \"binary\",\n",
    "    \"learning_rate\": CFG.learning_rate,\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    'seed': CFG.seed,\n",
    "    'n_jobs': -1, # -1でコア数をマックスで使う\n",
    "    'is_unbalance':True, # 不均衡データの場合にTrueにする\n",
    "}\n",
    "\n",
    "# 設定したハイパーパラメータを基にモデルを作成\n",
    "model = lgb.train(**best_params)\n",
    "# 学習\n",
    "model.fit(train_df[features], train_df[CFG.target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測\n",
    "prediction = model.predict_proba(test_df.drop([\"Id\", \"Class\"], axis=1))\n",
    "# 提出用に値を変換\n",
    "submission = pd.DataFrame(columns = submission_df.columns)\n",
    "submission['Id'] = test_df['Id']\n",
    "submission[['class_0','class_1']] = prediction\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
